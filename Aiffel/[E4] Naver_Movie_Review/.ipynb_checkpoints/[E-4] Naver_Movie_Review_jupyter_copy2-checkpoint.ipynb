{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_table('~/aiffel/sentiment_classification/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/sentiment_classification/ratings_test.txt')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "tokenizer = Mecab()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "def load_data(train_data, test_data, num_words=10000): \n",
    "    # 데이터의 중복 제거 및 NaN 결측치 제거\n",
    "    train_data.drop_duplicates(subset = ['document'], inplace=True) \n",
    "    #subset은 중복데이터를 처리할 열을 입력, inplace는 메서드가 적용되는 원본 데이터를 변경할지 여부를 결정\n",
    "    train_data = train_data.dropna(how ='any')\n",
    "    # how = 'any' -> NA(결측치)값이 존재하면 그 행이나 열을 drop함.\n",
    "    # 참고 : https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html\n",
    "    test_data.drop_duplicates(subset = ['document'], inplace=True) \n",
    "    test_data = test_data.dropna(how ='any')\n",
    "    \n",
    "    # 한국어 토크나이저로 토큰화 및 불용어 제거\n",
    "    X_train = []\n",
    "    for sentence in train_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence)\n",
    "        # Mecab의 morphs 기능을 통해 형태소로 구문분석\n",
    "        # 참고 : https://konlpy-ko.readthedocs.io/ko/v0.4.3/api/konlpy.tag/\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] \n",
    "        # 구분한 형태소 중 stopwords에 존재하지 않는 것만 temp_X에 저장\n",
    "        X_train.append(temp_X)\n",
    "        \n",
    "    X_test = []\n",
    "    for sentence in test_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence)\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] \n",
    "        X_test.append(temp_X)\n",
    "    \n",
    "    #?? concatenate는 배열을 붙이는 거라는 데 하나로 어떻게 합치지?\n",
    "    # ndarray클래스이 tolist() 메소드를 이용해 list 객체를 구하여 words에 저장.\n",
    "    words = np.concatenate(X_train).tolist() \n",
    "    # 리스트의 나온 횟수만큼 counter 리스트에 저장\n",
    "    counter = Counter(words)\n",
    "    # 데이터 개수가 많은 순으로 정렬된 배열을  리턴하는 most_common사용\n",
    "    # 참고 : https://www.daleseo.com/python-collections-counter/\n",
    "    counter = counter.most_common(10000-4)\n",
    "    #사전에 정의되 있던 인덱스 + 문자열에서 추출한 문자를 \n",
    "    vocab = ['<PAD>', '<BOS>', '<UNK>', '<UNUSED>'] + [key for key, _ in counter]\n",
    "    \n",
    "    # 리스트 컨프리헨션 사용헤서 사전 word_to_index구성\n",
    "    # 참고 : https://wikidocs.net/16045\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "\n",
    "    \n",
    "    def wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in wordlist]\n",
    "\n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
    "\n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index\n",
    "  \n",
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 모델 구성을 위한 데이터 분석 및 가공\n",
    "total_data_text = list(X_train) + list(X_test)\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "#print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "#print('문장길이 최대 : ', np.max(num_tokens))\n",
    "#print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "#print('pad_sequences maxlen : ', maxlen)\n",
    "#print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146182, 41)\n"
     ]
    }
   ],
   "source": [
    "# 4. 모델 구성 및 validation set 구성\n",
    "X_train = keras.preprocessing.sequence.pad_sequences(X_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='pre', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "X_test = keras.preprocessing.sequence.pad_sequences(X_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='pre', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46182, 41)\n",
      "(46182,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 100000건 분리\n",
    "x_val = X_train[:100000]   \n",
    "y_val = y_train[:100000]\n",
    "\n",
    "# validation set을 제외한 나머지 \n",
    "partial_x_train = X_train[100000:]  \n",
    "partial_y_train = y_train[100000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 모델 1 LSTM 훈련 개시\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 32  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 32))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1940/1950 [============================>.] - ETA: 0s - loss: 0.3960 - acc: 0.8236\n",
      "Epoch 00001: val_acc improved from -inf to 0.84297, saving model to best_model.h5\n",
      "1950/1950 [==============================] - 9s 5ms/step - loss: 0.3960 - acc: 0.8235 - val_loss: 0.3588 - val_acc: 0.8430\n",
      "Epoch 2/10\n",
      "1947/1950 [============================>.] - ETA: 0s - loss: 0.3305 - acc: 0.8576\n",
      "Epoch 00002: val_acc improved from 0.84297 to 0.85553, saving model to best_model.h5\n",
      "1950/1950 [==============================] - 8s 4ms/step - loss: 0.3304 - acc: 0.8577 - val_loss: 0.3411 - val_acc: 0.8555\n",
      "Epoch 3/10\n",
      "1937/1950 [============================>.] - ETA: 0s - loss: 0.3063 - acc: 0.8694\n",
      "Epoch 00003: val_acc improved from 0.85553 to 0.86575, saving model to best_model.h5\n",
      "1950/1950 [==============================] - 8s 4ms/step - loss: 0.3060 - acc: 0.8694 - val_loss: 0.3216 - val_acc: 0.8658\n",
      "Epoch 4/10\n",
      "1949/1950 [============================>.] - ETA: 0s - loss: 0.2911 - acc: 0.8777\n",
      "Epoch 00004: val_acc did not improve from 0.86575\n",
      "1950/1950 [==============================] - 8s 4ms/step - loss: 0.2911 - acc: 0.8778 - val_loss: 0.3153 - val_acc: 0.8651\n",
      "Epoch 5/10\n",
      "1945/1950 [============================>.] - ETA: 0s - loss: 0.2802 - acc: 0.8819\n",
      "Epoch 00005: val_acc improved from 0.86575 to 0.86770, saving model to best_model.h5\n",
      "1950/1950 [==============================] - 8s 4ms/step - loss: 0.2802 - acc: 0.8819 - val_loss: 0.3131 - val_acc: 0.8677\n",
      "Epoch 6/10\n",
      "1948/1950 [============================>.] - ETA: 0s - loss: 0.2698 - acc: 0.8888\n",
      "Epoch 00006: val_acc did not improve from 0.86770\n",
      "1950/1950 [==============================] - 8s 4ms/step - loss: 0.2698 - acc: 0.8888 - val_loss: 0.3194 - val_acc: 0.8657\n",
      "Epoch 7/10\n",
      "1942/1950 [============================>.] - ETA: 0s - loss: 0.2609 - acc: 0.8931\n",
      "Epoch 00007: val_acc improved from 0.86770 to 0.87051, saving model to best_model.h5\n",
      "1950/1950 [==============================] - 8s 4ms/step - loss: 0.2610 - acc: 0.8930 - val_loss: 0.3019 - val_acc: 0.8705\n",
      "Epoch 8/10\n",
      "1950/1950 [==============================] - ETA: 0s - loss: 0.2520 - acc: 0.8978\n",
      "Epoch 00008: val_acc improved from 0.87051 to 0.87146, saving model to best_model.h5\n",
      "1950/1950 [==============================] - 8s 4ms/step - loss: 0.2520 - acc: 0.8978 - val_loss: 0.3043 - val_acc: 0.8715\n",
      "Epoch 9/10\n",
      "1940/1950 [============================>.] - ETA: 0s - loss: 0.2441 - acc: 0.9006\n",
      "Epoch 00009: val_acc did not improve from 0.87146\n",
      "1950/1950 [==============================] - 8s 4ms/step - loss: 0.2440 - acc: 0.9006 - val_loss: 0.3115 - val_acc: 0.8714\n",
      "Epoch 10/10\n",
      "1947/1950 [============================>.] - ETA: 0s - loss: 0.2364 - acc: 0.9048\n",
      "Epoch 00010: val_acc did not improve from 0.87146\n",
      "1950/1950 [==============================] - 8s 4ms/step - loss: 0.2363 - acc: 0.9047 - val_loss: 0.3064 - val_acc: 0.8706\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train, epochs=10, callbacks=[es, mc], batch_size=60, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXxU1f3/8deHXRYFAasSZVGsBAwhjoiFiiK1qBXUagVxrZaiUhdqv1K1VVF+tWoVUb5+Rb/axSi1tipfq1IXXMCNsAuUgggYQQQUENkMfH5/nJtkEiYhy0wmIe/n4zGPzL333DufmUA+c8655xxzd0REREprkO4ARESkdlKCEBGRhJQgREQkISUIERFJSAlCREQSUoIQEZGElCCkRphZQzPbYmaHJ7NsOpnZkWaW9PvEzWygma2I215iZt+vSNkqvNZjZnZTVc8v57p3mtkfk31dqVmN0h2A1E5mtiVuszmwA9gVbf/c3XMrcz133wW0THbZ+sDdv5uM65jZFcCF7n5S3LWvSMa1Zd+kBCEJuXvRH+joG+oV7v5aWeXNrJG7F9REbCJSM9TEJFUSNSH81cyeNrOvgQvN7AQze9/MNprZGjObYGaNo/KNzMzNrFO0/WR0/GUz+9rM3jOzzpUtGx0/zcz+Y2abzOxBM5thZpeWEXdFYvy5mS0zs6/MbELcuQ3N7H4z22BmHwODyvl8bjGzyaX2TTSz+6LnV5jZ4uj9fBx9uy/rWvlmdlL0vLmZ/SWKbSFwbILXXR5dd6GZDY72HwM8BHw/ar5bH/fZ3hZ3/sjovW8ws+fN7JCKfDZ7Y2ZnRfFsNLM3zOy7ccduMrPVZrbZzP4d9177mNnsaP9aM7unoq8nSeLueuhR7gNYAQwste9OYCdwJuGLxn7AccDxhJppF+A/wKiofCPAgU7R9pPAeiAGNAb+CjxZhbIHAV8DQ6Jjo4FvgUvLeC8VifEF4ACgE/Bl4XsHRgELgQygLfB2+C+U8HW6AFuAFnHX/gKIRdtnRmUMGABsA7KiYwOBFXHXygdOip7fC7wJtAE6AotKlf0JcEj0O7kgiuE70bErgDdLxfkkcFv0/NQoxmygGfDfwBsV+WwSvP87gT9Gz7tFcQyIfkc3RZ97Y6A7sBI4OCrbGegSPZ8JDIuetwKOT/f/hfr2UA1CqmO6u/+fu+92923uPtPdP3D3AndfDkwC+pdz/rPunufu3wK5hD9MlS37I2Cuu78QHbufkEwSqmCMv3P3Te6+gvDHuPC1fgLc7+757r4BuKuc11kOfERIXAA/ADa6e150/P/cfbkHbwCvAwk7okv5CXCnu3/l7isJtYL4133G3ddEv5OnCMk9VoHrAgwHHnP3ue6+HRgD9DezjLgyZX025RkKTHH3N6Lf0V3A/oREXUBIRt2jZspPos8OQqLvamZt3f1rd/+ggu9DkkQJQqrj0/gNMzvazP5pZp+b2WZgLNCunPM/j3u+lfI7pssqe2h8HO7uhG/cCVUwxgq9FuGbb3meAoZFzy8gJLbCOH5kZh+Y2ZdmtpHw7b28z6rQIeXFYGaXmtm8qClnI3B0Ba8L4f0VXc/dNwNfAR3iylTmd1bWdXcTfkcd3H0J8EvC7+GLqMny4KjoZUAmsMTMPjSz0yv4PiRJlCCkOkrf4vkI4Vvzke6+P/BbQhNKKq0hNPkAYGZGyT9opVUnxjXAYXHbe7sN96/AwOgb+BBCwsDM9gOeBX5HaP5pDfyrgnF8XlYMZtYFeBi4EmgbXfffcdfd2y25qwnNVoXXa0VoyvqsAnFV5roNCL+zzwDc/Ul370toXmpI+Fxw9yXuPpTQjPgH4O9m1qyasUglKEFIMrUCNgHfmFk34Oc18JovAjlmdqaZNQKuBdqnKMZngOvMrIOZtQVuLK+wu68FpgNPAEvcfWl0qCnQBFgH7DKzHwGnVCKGm8ystYVxIqPijrUkJIF1hFx5BaEGUWgtkFHYKZ/A08DlZpZlZk0Jf6jfcfcya2SViHmwmZ0UvfavCP1GH5hZNzM7OXq9bdFjF+ENXGRm7aIax6bove2uZixSCUoQkky/BC4h/Od/hPANOqWiP8LnA/cBG4AjgDmEcRvJjvFhQl/BAkIH6rMVOOcpQqfzU3ExbwSuB54jdPSeS0h0FXEroSazAngZ+HPcdecDE4APozJHA/Ht9q8CS4G1ZhbfVFR4/iuEpp7novMPJ/RLVIu7LyR85g8TktcgYHDUH9EUuJvQb/Q5ocZyS3Tq6cBiC3fJ3Quc7+47qxuPVJyFJluRfYOZNSQ0aZzr7u+kOx6Rukw1CKnzzGyQmR0QNVP8hnBnzIdpDkukzlOCkH1BP2A5oZliEHCWu5fVxCQiFaQmJhERSUg1CBERSWifmayvXbt23qlTp3SHISJSp8yaNWu9uye8NXyfSRCdOnUiLy8v3WGIiNQpZlbmjAApbWKK7i5ZEs3+OKaccudGM0XG4vb9OjpviZn9MJVxiojInlJWg4juR59ImKQsH5hpZlPcfVGpcq2Aa4gb0GNmmYQJvroT5nF5zcyO8rCQjIiI1IBU1iB6A8uiGSt3ApMpntky3h2EkZTb4/YNASa7+w53/wRYFl1PRERqSCr7IDpQctbJfML0vkXMrBdwmLu/aGY3lDr3/VLn7jEBm5mNAEYAHH54rV6+WGSf8+2335Kfn8/27dv3XljSrlmzZmRkZNC4cVlTce0plQki0cyURYMuohkd7wcurey5RTvcJxHm8ycWi2lAh0gNys/Pp1WrVnTq1Ikwia7UVu7Ohg0byM/Pp3Pnzns/IZLKJqZ8Sk5LnEGYI6dQK6AH8KaFNY/7AFOijuq9nZs0ubnQqRM0aBB+5ubu7QwRAdi+fTtt27ZVcqgDzIy2bdtWuraXyhrETMJqUJ0J874PJSyaAoC7byJuIRMzexO4wd3zzGwb8JSF9XsPBbqSgrl1cnNhxAjYujVsr1wZtgGGV3sOS5F9n5JD3VGV31XKahDuXkCYq34qsBh4xt0XmtnYwoXUyzl3IWEO+UXAK8DVqbiD6eabi5NDoa1bw34RkfoupeMg3P0ldz/K3Y9w93HRvt+6+5QEZU8qXK832h4Xnfddd385FfGtWlW5/SJSe2zYsIHs7Gyys7M5+OCD6dChQ9H2zp0VWzbisssuY8mSJeWWmThxIrlJanvu168fc+fOTcq1asI+M5K6Kg4/PDQrJdovIsmVmxtq56tWhf9j48ZVrym3bdu2RX9sb7vtNlq2bMkNN9xQooy74+40aJD4u/ATTzyx19e5+uqrqx5kHVevJ+sbNw6aNy+5r3nzsF9Ekqewv2/lSnAv7u9LxU0hy5Yto0ePHowcOZKcnBzWrFnDiBEjiMVidO/enbFjxxaVLfxGX1BQQOvWrRkzZgw9e/bkhBNO4IsvvgDglltuYfz48UXlx4wZQ+/evfnud7/Lu+++C8A333zDj3/8Y3r27MmwYcOIxWJ7rSk8+eSTHHPMMfTo0YObbroJgIKCAi666KKi/RMmTADg/vvvJzMzk549e3LhhRcm/TMrS71OEMOHw6RJ0LEjmIWfkyapg1ok2Wq6v2/RokVcfvnlzJkzhw4dOnDXXXeRl5fHvHnzePXVV1m0aNEe52zatIn+/fszb948TjjhBB5//PGE13Z3PvzwQ+65556iZPPggw9y8MEHM2/ePMaMGcOcOXPKjS8/P59bbrmFadOmMWfOHGbMmMGLL77IrFmzWL9+PQsWLOCjjz7i4osvBuDuu+9m7ty5zJs3j4ceeqian07F1esEASEZrFgBu3eHn0oOIslX0/19RxxxBMcdd1zR9tNPP01OTg45OTksXrw4YYLYb7/9OO200wA49thjWbFiRcJrn3POOXuUmT59OkOHDgWgZ8+edO/evdz4PvjgAwYMGEC7du1o3LgxF1xwAW+//TZHHnkkS5Ys4dprr2Xq1KkccMABAHTv3p0LL7yQ3NzcSg10q656nyBEJPXK6tdLVX9fixYtip4vXbqUBx54gDfeeIP58+czaNCghOMBmjRpUvS8YcOGFBQUJLx206ZN9yhT2YXXyirftm1b5s+fT79+/ZgwYQI///nPAZg6dSojR47kww8/JBaLsWtXzUxLpwQhIimXzv6+zZs306pVK/bff3/WrFnD1KlTk/4a/fr145lnngFgwYIFCWso8fr06cO0adPYsGEDBQUFTJ48mf79+7Nu3TrcnfPOO4/bb7+d2bNns2vXLvLz8xkwYAD33HMP69atY2vp9roUqdd3MYlIzShsuk3mXUwVlZOTQ2ZmJj169KBLly707ds36a/xi1/8gosvvpisrCxycnLo0aNHUfNQIhkZGYwdO5aTTjoJd+fMM8/kjDPOYPbs2Vx++eW4O2bG73//ewoKCrjgggv4+uuv2b17NzfeeCOtWrVK+ntIZJ9ZkzoWi7kWDBKpOYsXL6Zbt27pDqNWKCgooKCggGbNmrF06VJOPfVUli5dSqNGtes7eKLfmZnNcvdYovK1K3oRkTpoy5YtnHLKKRQUFODuPPLII7UuOVRF3X8HIiJp1rp1a2bNmpXuMJJOndQiIpKQEoSIiCSkBCEiIgkpQYiISEJKECJSJ5100kl7DHobP348V111VbnntWzZEoDVq1dz7rnnlnntvd02P378+BID1k4//XQ2btxYkdDLddttt3HvvfdW+zrJoAQhInXSsGHDmDx5col9kydPZtiwYRU6/9BDD+XZZ5+t8uuXThAvvfQSrVu3rvL1aqOUJggzG2RmS8xsmZmNSXB8pJktMLO5ZjbdzDKj/Y3N7E/RscVm9utUxikidc+5557Liy++yI4dOwBYsWIFq1evpl+/fkXjEnJycjjmmGN44YUX9jh/xYoV9OjRA4Bt27YxdOhQsrKyOP/889m2bVtRuSuvvLJoqvBbb70VgAkTJrB69WpOPvlkTj75ZAA6derE+vXrAbjvvvvo0aMHPXr0KJoqfMWKFXTr1o2f/exndO/enVNPPbXE6yQyd+5c+vTpQ1ZWFmeffTZfffVV0etnZmaSlZVVNEngW2+9VbRgUq9evfj666+r/NkWStk4CDNrCEwEfgDkAzPNbIq7x09S8pS7/09UfjBwHzAIOA9o6u7HmFlzYJGZPe3uK1IVr4hU3XXXQbIXSsvOhuhva0Jt27ald+/evPLKKwwZMoTJkydz/vnnY2Y0a9aM5557jv3335/169fTp08fBg8eXOa6zA8//DDNmzdn/vz5zJ8/n5ycnKJj48aN48ADD2TXrl2ccsopzJ8/n2uuuYb77ruPadOm0a5duxLXmjVrFk888QQffPAB7s7xxx9P//79adOmDUuXLuXpp5/m0Ucf5Sc/+Ql///vfy13f4eKLL+bBBx+kf//+/Pa3v+X2229n/Pjx3HXXXXzyySc0bdq0qFnr3nvvZeLEifTt25ctW7bQrFmzSnzaiaWyBtEbWObuy919JzAZGBJfwN03x222AArn/XCghZk1AvYDdgLxZUVESjQzxTcvuTs33XQTWVlZDBw4kM8++4y1a9eWeZ2333676A91VlYWWVlZRceeeeYZcnJy6NWrFwsXLtzrRHzTp0/n7LPPpkWLFrRs2ZJzzjmHd955B4DOnTuTnZ0NlD+lOIT1KTZu3Ej//v0BuOSSS3j77beLYhw+fDhPPvlk0Yjtvn37Mnr0aCZMmMDGjRuTMpI7lSOpOwCfxm3nA8eXLmRmVwOjgSbAgGj3s4RksgZoDlzv7l8mOHcEMALgcK0TKpI25X3TT6WzzjqL0aNHM3v2bLZt21b0zT83N5d169Yxa9YsGjduTKdOnRJO8R0vUe3ik08+4d5772XmzJm0adOGSy+9dK/XKW9+u8KpwiFMF763Jqay/POf/+Ttt99mypQp3HHHHSxcuJAxY8Zwxhln8NJLL9GnTx9ee+01jj766Cpdv1AqaxCJ6nJ7fHLuPtHdjwBuBG6JdvcGdgGHAp2BX5pZlwTnTnL3mLvH2rdvn7zIRaROaNmyJSeddBI//elPS3ROb9q0iYMOOojGjRszbdo0ViZafD7OiSeeSG60/ulHH33E/PnzgTBVeIsWLTjggANYu3YtL7/8ctE5rVq1StjOf+KJJ/L888+zdetWvvnmG5577jm+//3vV/q9HXDAAbRp06ao9vGXv/yF/v37s3v3bj799FNOPvlk7r77bjZu3MiWLVv4+OOPOeaYY7jxxhuJxWL8+9//rvRrlpbKGkQ+cFjcdgawupzyk4GHo+cXAK+4+7fAF2Y2A4gBy1MRqIjUXcOGDeOcc84pcUfT8OHDOfPMM4nFYmRnZ+/1m/SVV17JZZddRlZWFtnZ2fTu3RsIq8P16tWL7t277zFV+IgRIzjttNM45JBDmDZtWtH+nJwcLr300qJrXHHFFfTq1avc5qSy/OlPf2LkyJFs3bqVLl268MQTT7Br1y4uvPBCNm3ahLtz/fXX07p1a37zm98wbdo0GjZsSGZmZtHqeNWRsum+o/6D/wCnAJ8BM4EL3H1hXJmu7r40en4mcKu7x8zsRuBo4KeEJqaZwFB3n1/W62m6b5Gapem+655aM923uxeY2ShgKtAQeNzdF5rZWCDP3acAo8xsIPAt8BVwSXT6ROAJ4CNCU9UT5SUHERFJvpRO9+3uLwEvldr327jn15Zx3hbCra4iIpImGkktIlW2r6xIWR9U5XelBCEiVdKsWTM2bNigJFEHuDsbNmyo9OA5rSgnIlWSkZFBfn4+69atS3coUgHNmjUjIyOjUucoQYhIlTRu3JjOnTunOwxJITUxiYhIQkoQIiKSkBKEiIgkpAQhIiIJKUGIiEhCShAiIpKQEoSIiCSkBCEiIgkpQYiISEJKECIikpAShIiIJKQEISIiCaU0QZjZIDNbYmbLzGxMguMjzWyBmc01s+lmlhl3LMvM3jOzhVGZys1TKyIi1ZKyBGFmDQlLh54GZALD4hNA5Cl3P8bds4G7gfuicxsBTwIj3b07cBJhWVIREakhqaxB9AaWuftyd98JTAaGxBdw981xmy2AwpVHTgXmu/u8qNwGd9+VwlhFRKSUVCaIDsCncdv50b4SzOxqM/uYUIO4Jtp9FOBmNtXMZpvZfyV6ATMbYWZ5ZpZX1UVL3OGmm2D58iqdLiKyz0plgrAE+/ZYm9DdJ7r7EcCNwC3R7kZAP2B49PNsMzslwbmT3D3m7rH27dtXKcilS+Ghh6BHD7j/ftileoqICJDaBJEPHBa3nQGsLqf8ZOCsuHPfcvf17r4VeAnISUWQRx0FixbBKafA6NHwve/BRx+l4pVEROqWVCaImUBXM+tsZk2AocCU+AJm1jVu8wxgafR8KpBlZs2jDuv+wKJUBZqRAVOmwNNPh6amnBy4/XbYuTNVrygiUvulLEG4ewEwivDHfjHwjLsvNLOxZjY4KjYquo11LjAauCQ69yvCHU0zgbnAbHf/Z6piBTCDoUNh8WI47zy47TY49lj48MNUvqqISO1l7nt0C9RJsVjM8/Lykna9F1+EkSNhzRq47joYOxZatEja5UVEagUzm+XusUTHNJK6DD/6UeibGDEC7rsPsrLgjTfSHZWISM1RgijH/vvDww/Dm29Cw4ahI/tnP4ONG9MdmYhI6ilBVED//jBvHtx4IzzxBGRmwgsvpDsqEZHUUoKooP32g7vugg8+gIMOgrPOgvPPh7Vr0x2ZiEhqKEFU0rHHwsyZcOed8PzzoTbxl7+EEdkiIvsSJYgqaNwYbr4Z5s6Fo4+Giy+G00+HlSvTHZmISPIoQVRDt27wzjvw4IPhZ48eMHEi7N6d7shERKpPCaKaGjSAUaNg4ULo2zc8P/FEWLIk3ZGJiFSPEkSSdOwIL78Mf/xjGD/Rsyf87nfwrVaxEJE6SgkiiczgkktCgjjzzDCNeO/eMHt2uiMTEak8JYgUOPhg+Nvf4B//gM8/D0ni17+GbdvSHZmISMUpQaTQ2WeH2sSll4YxFNnZoTNbRKQuUIJIsTZt4LHH4NVXQ3/EiSfC1VfD5s17P1dEJJ2UIGrIwIGwYEGYGfbhh8MtsS+9lO6oRETKpgRRg1q0CMuavvsutGoFZ5wBF10E69enOzIRkT2lNEGY2SAzW2Jmy8xsTILjI81sgZnNNbPpZpZZ6vjhZrbFzG5IZZw1rU+fcGfTb38LkyeH6Tr++ldN1yEitUvKEoSZNQQmAqcBmcCw0gkAeMrdj3H3bOBuwipy8e4HXk5VjOnUtGlY1nT2bOjUKaxmd9ZZ4a4nEZHaIJU1iN7AMndf7u47gcnAkPgC7h7fVdsCKPoObWZnAcuBhSmMMe2OOQbeew/+8Af417/CwkQvvpjuqEREUpsgOgCfxm3nR/tKMLOrzexjQg3immhfC+BG4PYUxldrNGwIo0fDrFlw6KFhkN2oURo3ISLplcoEYQn27dHK7u4T3f0IQkK4Jdp9O3C/u28p9wXMRphZnpnlrVu3rtoBp1tmZlhv4vrrw6R/sRjMn5/uqESkvkplgsgHDovbzgBWl1N+MnBW9Px44G4zWwFcB9xkZqNKn+Duk9w95u6x9u3bJyfqNGvaNKyBPXUqfPklHHccjB+vGWJFpOalMkHMBLqaWWczawIMBabEFzCzrnGbZwBLAdz9++7eyd07AeOB/+fuD6Uw1lrn1FND7eGHPww1itNPhzVr0h2ViNQnKUsQ7l4AjAKmAouBZ9x9oZmNNbPBUbFRZrbQzOYCo4FLUhVPXdS+fVj7+r//G956Sx3YIlKzzPeRm+9jsZjn5eWlO4yUWbwYhg2DefPgqqvgnnugefN0RyUidZ2ZzXL3WKJjGkldR3TrFjqwR48ONYpYLCQLEZFUUYKoQ5o2DeMlpk6Fr74K04jff786sEUkNZQg6qBTTw0T/w0aFGoUp52mDmwRST4liFogNzdMt9GgQfiZm7v3c9q1g+efDzPDvvNO6MCeMmXv54mIVJQSRJrl5sKIEbByZZisb+XKsF2RJGEGI0eGEdgZGTBkSOjA3ro19XGLyL5PCSLNbr55zz/oW7eG/RXVrRu8/z788pehRhGLwdy5yY1TROofJYg0W7WqcvvL0rQp3HtvmPBv40Y4/vgwIlsd2CJSVUoQaXb44ZXbvzc/+EEYgX3aaaFGMWiQOrBFpGqUINJs3Lg9B7w1bx72V1W7dvDcc/DIIzB9ephSXB3YIlJZShBpNnw4TJoEHTuGTueOHcP28OHVu65Z6OyePTvURoYMgSuvVAe2iFScptqoB3bsgFtuCX0URx8NTz0FvXqlOyoRqQ001UY917RpmLvp1Vdh8+bQgf2HP6gDW0TKpwRRjwwcGDqwzzgDbrghTCW+urwVOkSkXlOCqGfatoV//CN0YM+YEUZgv/BCuqMSkdpICaIeiu/A7tgRzjorjMhWB7aIxFOCqMeOPhreew9+9atQo8jJgTlz0h2ViNQWFUoQZnaEmTWNnp9kZteYWesKnDfIzJaY2TIzG5Pg+EgzW2Bmc81supllRvt/YGazomOzzGxAZd+YVEyTJnD33fDaa/D116ED+447YNEidWKL1HcVus01WhI0BnQiLCE6Bfiuu59ezjkNgf8APwDyCWtUD3P3RXFl9nf3zdHzwcBV7j7IzHoBa919tZn1AKa6e4fyYtRtrtW3YQP87GdhkB1Amzbwve9Bv37Qty8cdxw0a5beGEUkucq7zbVRBa+x290LzOxsYLy7P2hme2uM6A0sc/flURCTgSFAUYIoTA6RFoBH++OvvRBoZmZN3X1HBeOVKijswF62LIzAnjEj/PznP8Pxxo3DRIB9+4ak8b3vhXWzRWTfVNEE8a2ZDQMuAc6M9jXeyzkdgE/jtvOB40sXMrOrgdFAEyBRU9KPgTmJkoOZjQBGABxe1cmLZA9HHhkel14attevh3ffDQljxgyYMCEMugM46qjiGkbfvmHbLG2h71PcYfny8NnPnh3m2Tq9zDq7SPJVtIkpExgJvOfuT5tZZ+B8d7+rnHPOA37o7ldE2xcBvd39F2WUvyAqf0ncvu6E5qxT3f3j8mJUE1PN2b49rEFRWMuYMQO+/DIca9++ZLNUTk4YqCd7t317SATvvlv8WLs2HGvYEHbtgqFD4YEH4KCD0hur7DvKa2Kq9FQbZtYGOMzd5++l3AnAbe7+w2j71wDu/rsyyjcAvnL3A6LtDOAN4DJ3n7G3uJQg0mf3bliypLhJasaM0EwFITn07l3cLHXCCXDggemNt7ZYu7ZkMsjLg507w7EjjgiJtvDRtWuotd15J7RsGaZyv/hi1dak+qqdIMzsTWAwoUlqLrAOeMvdR5dzTiNCJ/UpwGeETuoL3H1hXJmu7r40en4mcKu7x6I7pN4Cxrr73yvyJpUgape1a4trF9Onh2/GBQXhWGZmyWapLl32/T90u3bBwoUlE8LHUZ24SZPQt1OYDE44AQ4+OPF1Fi8ONxLMmBFGxj/ySPj8RKoqGQlijrv3MrMrCLWHW81svrtn7eW804HxQEPgcXcfZ2ZjgTx3n2JmDwADgW+Br4BR7r7QzG4Bfg0sjbvcqe7+RVmvpQRRu23dCjNnFtcw3n0XNm0Kxw4+uDhZ9OsH2dmhQ7wu27wZPvigOBm8/37YB6F5qG/f4oRw7LGVa4bbvTskhhtvDEl37Fi47jpoVNEeRZE4yUgQC4BTgT8BN7v7zIokiJqkBFG37N4dvlHHN0utWBGONW8emqWys8Mf03bt9nwceGBol68N3OGTT0rWDhYsCO/RLKzHUZgM+vaFzp2TU2PKz4errw5rfeTkwGOPaZZeqbxkJIjzgN8AM9z9SjPrAtzj7j9ObqhVpwRR9332WcmE8e9/lz39h1kYp5EoeZT1OOAAaJCEuQN27NizM/nzz8OxVq2gT5/ihHD88eF1U8Ud/v53GDUq3G12ww1w662w336pe03ZtyS1k7q2UoLYN23bFgbwrV9fsce6dcUdvaU1bBjGelQmqbRsGa5ZujN5R3TTdZcuJWsH3bunp2bz1VdhypT//d/QwT1pEgzQ/ANSAcmoQWQADwJ9CYPZpgPXunt+MgOtDiUIgfCN+ptvKp5QCh+7diW+XuPG8O234XmTJqG/oDAZlNeZnC5vvCkGsIgAABF1SURBVBEmYvz4Y/jpT8OdT23apDsqqc2SkSBeBZ4C/hLtuhAY7u4/SFqU1aQEIVXlHjrMy0oebdsWj+moC1ONbNsGt98ekkO7dvDgg3Duufv+nWJSNclIEHPdPXtv+9JJCUKkpDlz4IorQn/J4MEwcSJkZKQ7qrpt9+5wA8Lrr4fHZ59Bjx7hhorsbOjZs+5NP5OMuZjWm9mFwNPR9jBgQzKCE5HU6NUr3Gr7wAPwm9+E8Se//z38/OfJ6ayvDwqnOylMCG+8EWqVEAYvdukCb74JubnF5xx6aHHCKEwaRx5ZNz/zitYgDgceAk4g9EG8C1zj7qtSG17FqQYhUrbly0NieO210Fz26KPQrVu6o6qdPv88JILCpLByZdh/yCFwyinFj8MOKz5n/XqYNw/mzi1+LF5c3LfVokVYvbEwYWRnh9ufmzev+fdXWkruYjKz69x9fLUiSyIlCJHyucOf/wzXXx868m+5JQy2a9Ik3ZGl16ZN8NZbxQlhYTTXQ+vWcPLJIRkMGBAW2KpMP8727WFdlblzSyaPwgGTDRqEyS0LE0bho6ZvfEhVgljl7rVmClUlCJGKWbs2jLyePDnclvvoo+GOrPpi+/Zwu3JhQsjLC9/099svjOQvrCH06pX8W5bdw4DQ0rWNwloKhMGhpZuojjoqdSPlU5UgPnX3w/ZesmYoQVRfbi7cfDOsWgWHHw7jxsHw4emOSlLlxRfhyitDR+uoUeH33apVuqNKvl27wuzDhQlhxoyQJBo2DCP2CxPCCSekb+bhr76C+fOLE8a8efDRR8W3WDdrFpqk4puosrKS8/tSDUL2Kjc33D8fP3K5efMw4EpJYt/19ddw003Fdzg9/DCccUa6o6oe99D+X5gQ3nyzeN6vY44pTggnngj775/WUMu1c2eYTaB0E1Xh1PoQBkVmZ8P3vw/XXlu116lygjCzr4lWeSt9CNjP3WvN9GBKENXTqVPJam6hjh2L50iSfdd774VbYhctgmHDYPz4urXmxKpVJe80WrMm7O/cuTghDBhQt95TIu5hDq7STVSdO8Orr1btmppqQ/aqQYPwj680s3Dvt+z7duwIt8HeeWdourj/frjooto5wG79epg2rTgpFK4/ctBBIREUJoXOndMbZ00pKKh6H4UShOyVahBSaNGisObEu++GZU4feaRm/tB+803oQC/r8cUXxc8Lm4xatYL+/YsTQo8etTOh1WbJGCgn+7hx4xL3QYwbl76YJD0yM+Gdd+B//ifcBtujB9xxB1xzTeW+pbqHPo7y/ujHP775JvF12rSB73wnPLKzw8+MjNDuftxxWgcjlVSDkCK6i0lK+/RTuOqqcMfTsceGNSc6dqz4H/3t2/e8plmY36rwj355j4MO0jiNVEtbE5OZDQIeIKwo95i731Xq+EjgamAXsAUY4e6LomO/Bi6Pjl3j7lPLey0lCJHUcIe//Q1+8YvQzJNIgwZhDqKK/NFv317f+muTtCQIM2tIWJP6B0A+YU3qYYUJICqzv7tvjp4PBq5y90FmlkmY96k3cCjwGnCUu5cxKbMShEiqffllqEE0arTnH/22bWvPCn9SOenqg+gNLHP35VEQk4EhQFGCKEwOkRYU31I7BJjs7juAT8xsWXS991IYr4iU48AD4b/+K91RSE1KZYLoAHwat50PHF+6kJldDYwGmgCFa2B1AN4vdW6HBOeOAEYAHH54rRmzJyKyT0jlBLSJbjbboz3L3Se6+xHAjcAtlTx3krvH3D3Wvq5Nwi4iUsulMkHkA/FzNWUAq8spPxk4q4rniohIkqUyQcwEuppZZzNrAgwFpsQXMLOucZtnAEuj51OAoWbW1Mw6A12BD1MYq4iIlJKyPgh3LzCzUcBUwm2uj7v7QjMbC+S5+xRglJkNBL4FvgIuic5daGbPEDq0C4Cry7uDSUREkk8D5URE6rHybnOtg6ukiohITVCCEBGRhJQgpNbJzQ2zyzZoEH7m5qY7IpH6STOiSK1SemW7lSvDNmjiQJGaphqE1Co331xyynEI2zffnJ54ROozJQipVVatqtx+EUkdJQipVcqaUktTbYnUPCUIqVXGjQsr2cXTynYi6aEEIbXK8OEwaVJYtcws/Jw0SR3UIumgu5ik1hk+XAlBpDZQDUJERBJSghARkYSUIEREJCElCBERSUgJQkREElKCEBGRhFKaIMxskJktMbNlZjYmwfHRZrbIzOab2etm1jHu2N1mttDMFpvZBDOzVMYqUppmlZX6LmUJwswaAhOB04BMYJiZZZYqNgeIuXsW8Cxwd3Tu94C+QBbQAzgO6J+qWEVKK5xVduVKcC+eVVZJQuqTVNYgegPL3H25u+8EJgND4gu4+zR3L5y7830go/AQ0AxoAjQFGgNrUxirSAmaVVYktQmiA/Bp3HZ+tK8slwMvA7j7e8A0YE30mOrui0ufYGYjzCzPzPLWrVuXtMBFNKusSGoTRKI+A09Y0OxCIAbcE20fCXQj1Cg6AAPM7MQ9LuY+yd1j7h5r37590gIX0ayyIqlNEPnAYXHbGcDq0oXMbCBwMzDY3XdEu88G3nf3Le6+hVCz6JPCWEVK0KyyIqlNEDOBrmbW2cyaAEOBKfEFzKwX8AghOXwRd2gV0N/MGplZY0IH9R5NTCKpolllRVI4m6u7F5jZKGAq0BB43N0XmtlYIM/dpxCalFoCf4vuYl3l7oMJdzQNABYQmqVecff/S1WsIoloVlmp78w9YbdAnROLxTwvLy/dYYiI1ClmNsvdY4mOaSS1iIgkpAQhIiIJKUGIiEhCShAiIpKQEoRILadJAyVdUnabq4hUX+GkgYXzQhVOGgi6BVdSTzUIkVpMkwZKOilBiNRimjRQ0kkJQqQW06SBkk5KECK1mCYNlHRSghCpxTRpoKST7mISqeU0aaCki2oQIiKSkBKEiIgkpAQhIhWiEd31T0oThJkNMrMlZrbMzMYkOD7azBaZ2Xwze93MOsYdO9zM/mVmi6MynVIZq4iUrXBE98qV4F48oltJYt+WsgRhZg2BicBpQCYwzMwySxWbA8TcPYuwitzdccf+DNzj7t2A3sAXiEhaaER3/ZTKGkRvYJm7L3f3ncBkYEh8AXef5u6F/+zeBzIAokTSyN1fjcptiSsnIjVMI7rrp1QmiA7Ap3Hb+dG+slwOvBw9PwrYaGb/MLM5ZnZPVCMRkTTQiO76KZUJwhLsS7gAtpldCMSAe6JdjYDvAzcAxwFdgEsTnDfCzPLMLG/dunXJiFlEEtCI7voplQkiHzgsbjsDWF26kJkNBG4GBrv7jrhz50TNUwXA80BO6XPdfZK7x9w91r59+6S/AREJNKK7fkrlSOqZQFcz6wx8BgwFLogvYGa9gEeAQe7+Ralz25hZe3dfBwwA8lIYq4jshUZ01z8pq0FE3/xHAVOBxcAz7r7QzMaa2eCo2D1AS+BvZjbXzKZE5+4iNC+9bmYLCM1Vj6YqVhER2ZO5J+wWqHNisZjn5amSISJSGWY2y91jiY5pJLWIiCSkBCEiIgkpQYhInaH5oGqW1oMQkTqhcD6owik/CueDAt1dlSqqQYhInaD5oGqeEoSI1AmaD6rmKUGISJ2g+aBqnhKEiNQJmg+q5ilBiEidoPmgap7uYhKROkPzQdUs1SBERCQhJQgRkUqqLwP21MQkIlIJ9WnAnmoQIiKVUJ8G7ClBiIhUQn0asKcEISJSCfVpwF5KE4SZDTKzJWa2zMzGJDg+2swWmdl8M3vdzDqWOr6/mX1mZg+lMk4RkYqqTwP2UpYgzKwhMBE4DcgEhplZZqlic4CYu2cBzwJ3lzp+B/BWqmIUEams+jRgL5U1iN7AMndf7u47gcnAkPgC7j7N3Qu7e94HMgqPmdmxwHeAf6UwRhGRShs+HFasgN27w899MTlAahNEB+DTuO38aF9ZLgdeBjCzBsAfgF+V9wJmNsLM8swsb926ddUMV0RE4qUyQViCfZ6woNmFQAy4J9p1FfCSu3+aqHzRxdwnuXvM3WPt27evVrAiIlJSKhNEPnBY3HYGsLp0ITMbCNwMDHb3HdHuE4BRZrYCuBe42MzuSmGsIiJ1TqpHdKdyJPVMoKuZdQY+A4YCF8QXMLNewCPAIHf/onC/uw+PK3MpoSN7j7ugRETqq5oY0Z2yGoS7FwCjgKnAYuAZd19oZmPNbHBU7B6gJfA3M5trZlNSFY+IyL6kJkZ0m3vCboE6JxaLeV5eXrrDEBGpEQ0aQKI/32bh7qqKMrNZ7h5L+BpVDU5ERNKnJkZ0K0GIiNRBNTGiWwlCRKQOqokR3VoPQkSkjkr1EqyqQYiISEJKECIikpAShIiIJKQEISIiCSlBiIhIQvvMSGozWwesTHcc1dQOWJ/uIGoRfR4l6fMops+ipOp8Hh3dPeF02PtMgtgXmFleWUPe6yN9HiXp8yimz6KkVH0eamISEZGElCBERCQhJYjaZVK6A6hl9HmUpM+jmD6LklLyeagPQkREElINQkREElKCEBGRhJQgagEzO8zMppnZYjNbaGbXpjumdDOzhmY2x8xeTHcs6WZmrc3sWTP7d/Rv5IR0x5ROZnZ99P/kIzN72syapTummmRmj5vZF2b2Udy+A83sVTNbGv1sk4zXUoKoHQqAX7p7N6APcLWZZaY5pnS7lrCWucADwCvufjTQk3r8uZhZB+AaIObuPYCGwND0RlXj/ggMKrVvDPC6u3cFXo+2q00JohZw9zXuPjt6/jXhD0CH9EaVPmaWAZwBPJbuWNLNzPYHTgT+F8Ddd7r7xvRGlXaNgP3MrBHQHFid5nhqlLu/DXxZavcQ4E/R8z8BZyXjtZQgahkz6wT0Aj5IbyRpNR74L6ASS6/vs7oA64Anoia3x8ysRbqDShd3/wy4F1gFrAE2ufu/0htVrfAdd18D4QsncFAyLqoEUYuYWUvg78B17r453fGkg5n9CPjC3WelO5ZaohGQAzzs7r2Ab0hS80FdFLWtDwE6A4cCLczswvRGte9SgqglzKwxITnkuvs/0h1PGvUFBpvZCmAyMMDMnkxvSGmVD+S7e2GN8llCwqivBgKfuPs6d/8W+AfwvTTHVBusNbNDAKKfXyTjokoQtYCZGaGNebG735fueNLJ3X/t7hnu3onQ+fiGu9fbb4ju/jnwqZl9N9p1CrAojSGl2yqgj5k1j/7fnEI97rSPMwW4JHp+CfBCMi7aKBkXkWrrC1wELDCzudG+m9z9pTTGJLXHL4BcM2sCLAcuS3M8aePuH5jZs8Bswt1/c6hn026Y2dPASUA7M8sHbgXuAp4xs8sJSfS8pLyWptoQEZFE1MQkIiIJKUGIiEhCShAiIpKQEoSIiCSkBCEiIgkpQYjshZntMrO5cY+kjWQ2s07xs3KK1CYaByGyd9vcPTvdQYjUNNUgRKrIzFaY2e/N7MPocWS0v6OZvW5m86Ofh0f7v2Nmz5nZvOhROEVEQzN7NFrj4F9mtl9U/hozWxRdZ3Ka3qbUY0oQInu3X6kmpvPjjm12997AQ4RZaIme/9nds4BcYEK0fwLwlrv3JMyntDDa3xWY6O7dgY3Aj6P9Y4Be0XVGpurNiZRFI6lF9sLMtrh7ywT7VwAD3H15NNni5+7e1szWA4e4+7fR/jXu3s7M1gEZ7r4j7hqdgFejhV4wsxuBxu5+p5m9AmwBngeed/ctKX6rIiWoBiFSPV7G87LKJLIj7vkuivsGzwAmAscCs6IFckRqjBKESPWcH/fzvej5uxQvgzkcmB49fx24EorW3N6/rIuaWQPgMHefRlg8qTWwRy1GJJX0jURk7/aLm2UXwvrQhbe6NjWzDwhftoZF+64BHjezXxFWgyucffVaYFI04+YuQrJYU8ZrNgSeNLMDAAPu11KjUtPUByFSRVEfRMzd16c7FpFUUBOTiIgkpBqEiIgkpBqEiIgkpAQhIiIJKUGIiEhCShAiIpKQEoSIiCT0/wFMLboJkYDZMgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 6. Loss, Accuracy 그래프 시각화\n",
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['acc']\n",
    "val_acc = history_dict['val_acc']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 2s - loss: 0.3087 - acc: 0.8696\n",
      "[0.30865487456321716, 0.8695607781410217]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (3.8.3)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from gensim) (4.1.0)\n",
      "Requirement already satisfied: six>=1.5.0 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from gensim) (1.19.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/ko.tsv'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00545231,  0.59479386, -0.5650456 ,  0.6148988 ,  0.49764812,\n",
       "       -0.4592151 ,  0.87130654,  0.7049026 ,  0.0335626 ,  0.17589828,\n",
       "        0.30301404, -0.04730422,  0.2827968 ,  0.43540958,  0.05599823,\n",
       "        0.6517034 , -0.7126021 , -0.2606518 ,  0.13326332,  0.10878755,\n",
       "       -0.19412017,  0.15452592, -0.5049098 ,  0.515646  ,  0.25049362,\n",
       "        0.19701932, -0.46641982, -0.75827014, -0.198063  , -0.33578527,\n",
       "       -0.16979237, -0.6211356 ], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['사랑']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('위대', 0.9734489917755127),\n",
       " ('비극', 0.9702250957489014),\n",
       " ('생각나', 0.9681748151779175),\n",
       " ('슬프', 0.9681433439254761),\n",
       " ('강렬', 0.9666721820831299),\n",
       " ('발견', 0.9660415649414062),\n",
       " ('귀여운', 0.9644383788108826),\n",
       " ('진실', 0.9632236957550049),\n",
       " ('감탄', 0.9625881910324097),\n",
       " ('빠져', 0.9623256325721741)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"사랑\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ssac12/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.3740246 , -1.7353463 ,  3.3915305 , -2.569253  , -1.4016607 ,\n",
       "        1.4556127 ,  0.9414557 ,  1.9207907 ,  0.16471806,  0.4838317 ,\n",
       "       -0.8547181 ,  2.0879807 ,  0.86741775,  0.87539405, -0.09962013,\n",
       "        0.22928311, -1.1858722 ,  0.00858838,  1.4999928 , -0.16196461,\n",
       "       -0.35184434, -0.92390764,  1.0849575 ,  0.3025011 ,  2.7021565 ,\n",
       "       -1.0263684 ,  0.32864776, -0.76589465, -2.510981  , -0.66225356,\n",
       "        2.8434615 ,  0.50130975, -1.021874  , -1.4366034 ,  1.1110784 ,\n",
       "        0.5812605 , -0.5830406 , -0.5785423 ,  1.3634988 ,  2.3074338 ,\n",
       "       -1.4314893 ,  0.45745876,  1.1073523 , -3.2135262 , -0.2898375 ,\n",
       "       -1.1622221 ,  1.2369208 , -0.7622987 , -0.37757635,  1.1376442 ,\n",
       "        0.01065568, -0.69105595,  1.5159112 ,  1.1534518 , -1.0119992 ,\n",
       "       -0.5757404 ,  1.1349088 , -1.1289831 ,  0.13004152,  2.0451715 ,\n",
       "       -0.23940353,  1.3604902 ,  0.72700524,  0.32545742,  1.0612459 ,\n",
       "        0.42252553,  1.1442151 ,  2.8774905 ,  2.4377263 , -1.340305  ,\n",
       "        0.12629706, -0.07772489, -0.59053177, -0.19007324,  0.1396541 ,\n",
       "       -1.8655105 ,  0.9401054 ,  0.5150856 ,  0.7795373 , -0.86505556,\n",
       "        0.11842118, -1.8303713 ,  1.337177  , -1.0102932 , -0.37180334,\n",
       "        0.00893255, -0.49141577, -1.05802   , -2.5987291 ,  0.9731856 ,\n",
       "        0.34080654, -2.5973568 ,  1.0046519 , -1.3914212 , -0.6504351 ,\n",
       "       -0.9010805 , -1.1341541 ,  0.75565654,  1.2941337 ,  0.0880572 ,\n",
       "       -1.0341461 , -0.1750075 , -0.01880708, -1.0835075 , -2.0333962 ,\n",
       "        1.1372623 ,  1.0626172 , -1.8369784 , -2.2662086 , -3.382057  ,\n",
       "        1.6751666 , -0.2988223 , -0.25563756, -1.5594274 ,  0.6313433 ,\n",
       "       -1.2667153 , -1.6857744 , -1.0949599 ,  0.7742313 , -0.6095523 ,\n",
       "        3.19503   ,  0.13200459,  1.7937473 , -2.8782516 ,  1.3821276 ,\n",
       "        2.2895143 ,  0.0741943 , -0.41046414,  1.438796  ,  0.19373988,\n",
       "        1.4294034 ,  1.5025262 ,  1.4849502 ,  1.5754777 ,  2.7793512 ,\n",
       "       -0.6885003 , -0.30154693, -1.708323  ,  1.1030879 , -2.2597387 ,\n",
       "        1.1909146 ,  2.4399316 ,  0.3990314 ,  0.904154  ,  0.5454401 ,\n",
       "       -1.3235748 , -0.64812386,  0.22390233,  0.9657619 , -0.47360668,\n",
       "       -0.10278235, -1.0679734 , -0.91414386,  0.92069   ,  0.3549338 ,\n",
       "        0.32858834,  0.84870636,  3.596926  , -1.6651102 ,  0.23658653,\n",
       "        1.0515738 ,  0.40531915, -0.773514  , -0.93460965, -0.3946274 ,\n",
       "       -1.5657727 ,  1.183652  ,  2.5277    ,  0.57700926,  1.7051374 ,\n",
       "       -1.8249958 , -2.0328498 ,  0.6617798 ,  0.85747904,  0.31782728,\n",
       "       -1.1660796 ,  0.32923874,  2.2055087 , -0.12782003,  2.0455444 ,\n",
       "       -0.1724252 ,  0.46001154,  1.559042  , -1.6152996 , -0.84242785,\n",
       "        0.7553168 ,  0.39734274,  0.07714175,  0.05610155,  0.32837135,\n",
       "        1.0220716 ,  1.3816743 ,  0.8049544 ,  0.28728685, -0.97610044,\n",
       "        0.8861181 , -0.01250968, -1.4845604 , -1.5236791 , -1.5451258 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors, Word2Vec\n",
    "word2vec_path = os.getenv('HOME')+'/aiffel/sentiment_classification/ko.bin'\n",
    "word2vec = Word2Vec.load(word2vec_path)\n",
    "vector = word2vec['사랑']\n",
    "vector     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ssac12/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similar_by_word` (Method will be removed in 4.0.0, use self.wv.similar_by_word() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('슬픔', 0.7216663360595703),\n",
       " ('행복', 0.6759077310562134),\n",
       " ('절망', 0.6468985676765442),\n",
       " ('기쁨', 0.6458414793014526),\n",
       " ('이별', 0.6334798336029053),\n",
       " ('추억', 0.6320937871932983),\n",
       " ('인생', 0.6216273307800293),\n",
       " ('애정', 0.6206068992614746),\n",
       " ('연인', 0.6186063289642334),\n",
       " ('유혹', 0.5965287685394287)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#한국어 word2vec을 사용하고 나서 연관 단어가 더 잘 뜨는 것 확인 가능 \n",
    "word2vec.similar_by_word(\"사랑\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ssac12/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  \n",
      "/home/ssac12/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 200  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 41, 200)           2000000   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 35, 16)            22416     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 7, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1, 16)             1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,024,369\n",
      "Trainable params: 2,024,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 2 Conv1D + MaxPooling\n",
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 200  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "# 모델 구성\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 100)         2000000   \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 808       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,000,817\n",
      "Trainable params: 2,000,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 3 MaxPooling\n",
    "vocab_size = 20000  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 100   # 단어 하나를 표현하는 임베딩 벡터의 차원수입니다. \n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=10  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고 : https://wikidocs.net/44249"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
