{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_table('~/aiffel/sentiment_classification/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/sentiment_classification/ratings_test.txt')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "tokenizer = Mecab()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "def load_data(train_data, test_data, num_words=10000): \n",
    "    # 데이터의 중복 제거 및 NaN 결측치 제거\n",
    "    train_data.drop_duplicates(subset = ['document'], inplace=True) \n",
    "    #subset은 중복데이터를 처리할 열을 입력, inplace는 메서드가 적용되는 원본 데이터를 변경할지 여부를 결정\n",
    "    train_data = train_data.dropna(how ='any')\n",
    "    # how = 'any' -> NA(결측치)값이 존재하면 그 행이나 열을 drop함.\n",
    "    # 참고 : https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html\n",
    "    test_data.drop_duplicates(subset = ['document'], inplace=True) \n",
    "    test_data = test_data.dropna(how ='any')\n",
    "    \n",
    "    # 한국어 토크나이저로 토큰화 및 불용어 제거\n",
    "    X_train = []\n",
    "    for sentence in train_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence)\n",
    "        # Mecab의 morphs 기능을 통해 형태소로 구문분석\n",
    "        # 참고 : https://konlpy-ko.readthedocs.io/ko/v0.4.3/api/konlpy.tag/\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] \n",
    "        # 구분한 형태소 중 stopwords에 존재하지 않는 것만 temp_X에 저장\n",
    "        X_train.append(temp_X)\n",
    "        \n",
    "    X_test = []\n",
    "    for sentence in test_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence)\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] \n",
    "        X_test.append(temp_X)\n",
    "    \n",
    "    #?? concatenate는 배열을 붙이는 거라는 데 하나로 어떻게 합치지?\n",
    "    # ndarray클래스이 tolist() 메소드를 이용해 list 객체를 구하여 words에 저장.\n",
    "    words = np.concatenate(X_train).tolist() \n",
    "    # 리스트의 나온 횟수만큼 counter 리스트에 저장\n",
    "    counter = Counter(words)\n",
    "    # 데이터 개수가 많은 순으로 정렬된 배열을  리턴하는 most_common사용\n",
    "    # 참고 : https://www.daleseo.com/python-collections-counter/\n",
    "    counter = counter.most_common(10000-4)\n",
    "    #사전에 정의되 있던 인덱스 + 문자열에서 추출한 문자를 \n",
    "    vocab = ['<PAD>', '<BOS>', '<UNK>', '<UNUSED>'] + [key for key, _ in counter]\n",
    "    \n",
    "    # 리스트 컨프리헨션 사용헤서 사전 word_to_index구성\n",
    "    # 참고 : https://wikidocs.net/16045\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "\n",
    "    \n",
    "    def wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in wordlist]\n",
    "\n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
    "\n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index\n",
    "  \n",
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 모델 구성을 위한 데이터 분석 및 가공\n",
    "total_data_text = list(X_train) + list(X_test)\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "#print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "#print('문장길이 최대 : ', np.max(num_tokens))\n",
    "#print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "#print('pad_sequences maxlen : ', maxlen)\n",
    "#print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146182, 41)\n"
     ]
    }
   ],
   "source": [
    "# 4. 모델 구성 및 validation set 구성\n",
    "X_train = keras.preprocessing.sequence.pad_sequences(X_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='pre', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "X_test = keras.preprocessing.sequence.pad_sequences(X_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='pre', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46182, 41)\n",
      "(46182,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 100000건 분리\n",
    "x_val = X_train[:100000]   \n",
    "y_val = y_train[:100000]\n",
    "\n",
    "# validation set을 제외한 나머지 \n",
    "partial_x_train = X_train[100000:]  \n",
    "partial_y_train = y_train[100000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 한국어 Word2vec 적용 전 LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 32)          320000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 1312      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 321,393\n",
      "Trainable params: 321,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 5. 모델 1 LSTM 훈련 개시\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 32  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.LSTM(8))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "91/91 [==============================] - 1s 14ms/step - loss: 0.6449 - accuracy: 0.6815 - val_loss: 0.5546 - val_accuracy: 0.7782\n",
      "Epoch 2/10\n",
      "91/91 [==============================] - 1s 11ms/step - loss: 0.4653 - accuracy: 0.8267 - val_loss: 0.4205 - val_accuracy: 0.8313\n",
      "Epoch 3/10\n",
      "91/91 [==============================] - 1s 11ms/step - loss: 0.3641 - accuracy: 0.8603 - val_loss: 0.3854 - val_accuracy: 0.8352\n",
      "Epoch 4/10\n",
      "91/91 [==============================] - 1s 11ms/step - loss: 0.3162 - accuracy: 0.8767 - val_loss: 0.3820 - val_accuracy: 0.8378\n",
      "Epoch 5/10\n",
      "91/91 [==============================] - 1s 11ms/step - loss: 0.2896 - accuracy: 0.8896 - val_loss: 0.3949 - val_accuracy: 0.8355\n",
      "Epoch 6/10\n",
      "91/91 [==============================] - 1s 11ms/step - loss: 0.2732 - accuracy: 0.8960 - val_loss: 0.3913 - val_accuracy: 0.8355\n",
      "Epoch 7/10\n",
      "91/91 [==============================] - 1s 11ms/step - loss: 0.2576 - accuracy: 0.9040 - val_loss: 0.4052 - val_accuracy: 0.8340\n",
      "Epoch 8/10\n",
      "91/91 [==============================] - 1s 11ms/step - loss: 0.2461 - accuracy: 0.9086 - val_loss: 0.4126 - val_accuracy: 0.8337\n",
      "Epoch 9/10\n",
      "91/91 [==============================] - 1s 11ms/step - loss: 0.2319 - accuracy: 0.9157 - val_loss: 0.4287 - val_accuracy: 0.8314\n",
      "Epoch 10/10\n",
      "91/91 [==============================] - 1s 11ms/step - loss: 0.2214 - accuracy: 0.9214 - val_loss: 0.4447 - val_accuracy: 0.8283\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "epochs = 10  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다.\n",
    "\n",
    "history = model.fit(partial_x_train, partial_y_train, epochs=epochs,\n",
    "                    batch_size=512, validation_data=(x_val, y_val), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 6. Loss, Accuracy 그래프 시각화\n",
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 2s - loss: 0.4550 - accuracy: 0.8235\n",
      "[0.45495355129241943, 0.823544979095459]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 한국어 Word2vec을 적용하기 전까진 LVSM을 활용한 모델의 정확도는 0.8235이였음.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (3.8.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from gensim) (4.1.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from gensim) (1.19.4)\n",
      "Requirement already satisfied: six>=1.5.0 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from gensim) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/ko.tsv'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.06177177, -0.05192802,  0.10857667, -0.09843153, -0.01438852,\n",
       "       -0.03119559, -0.06803627, -0.01153806, -0.02794645, -0.01330731,\n",
       "       -0.05015636, -0.01975377, -0.10839368, -0.06791034, -0.09030037,\n",
       "       -0.04467044,  0.05923732, -0.00917302,  0.06766815,  0.0259402 ,\n",
       "        0.08917043, -0.09576157, -0.08074431, -0.11231235, -0.0137303 ,\n",
       "        0.07821837,  0.03013974,  0.09122439, -0.01187937, -0.09402842,\n",
       "       -0.1061004 ,  0.04406529], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['사랑']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('>_', 0.8743342161178589),\n",
       " ('행복', 0.8668898344039917),\n",
       " ('눈물', 0.8479568362236023),\n",
       " ('조아', 0.833762526512146),\n",
       " ('+_+', 0.832385778427124),\n",
       " ('짱', 0.8303730487823486),\n",
       " ('미키루크', 0.829961359500885),\n",
       " ('!^^', 0.8288434743881226),\n",
       " ('터리', 0.8288329839706421),\n",
       " ('재미있', 0.8280861377716064)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"사랑\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### word2vec 적용 전 similar_by_word을 적용하면 상대적으로 관련성이 적은 단어들이 뜨는 것을 볼 수 있음\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ssac12/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.3740246 , -1.7353463 ,  3.3915305 , -2.569253  , -1.4016607 ,\n",
       "        1.4556127 ,  0.9414557 ,  1.9207907 ,  0.16471806,  0.4838317 ,\n",
       "       -0.8547181 ,  2.0879807 ,  0.86741775,  0.87539405, -0.09962013,\n",
       "        0.22928311, -1.1858722 ,  0.00858838,  1.4999928 , -0.16196461,\n",
       "       -0.35184434, -0.92390764,  1.0849575 ,  0.3025011 ,  2.7021565 ,\n",
       "       -1.0263684 ,  0.32864776, -0.76589465, -2.510981  , -0.66225356,\n",
       "        2.8434615 ,  0.50130975, -1.021874  , -1.4366034 ,  1.1110784 ,\n",
       "        0.5812605 , -0.5830406 , -0.5785423 ,  1.3634988 ,  2.3074338 ,\n",
       "       -1.4314893 ,  0.45745876,  1.1073523 , -3.2135262 , -0.2898375 ,\n",
       "       -1.1622221 ,  1.2369208 , -0.7622987 , -0.37757635,  1.1376442 ,\n",
       "        0.01065568, -0.69105595,  1.5159112 ,  1.1534518 , -1.0119992 ,\n",
       "       -0.5757404 ,  1.1349088 , -1.1289831 ,  0.13004152,  2.0451715 ,\n",
       "       -0.23940353,  1.3604902 ,  0.72700524,  0.32545742,  1.0612459 ,\n",
       "        0.42252553,  1.1442151 ,  2.8774905 ,  2.4377263 , -1.340305  ,\n",
       "        0.12629706, -0.07772489, -0.59053177, -0.19007324,  0.1396541 ,\n",
       "       -1.8655105 ,  0.9401054 ,  0.5150856 ,  0.7795373 , -0.86505556,\n",
       "        0.11842118, -1.8303713 ,  1.337177  , -1.0102932 , -0.37180334,\n",
       "        0.00893255, -0.49141577, -1.05802   , -2.5987291 ,  0.9731856 ,\n",
       "        0.34080654, -2.5973568 ,  1.0046519 , -1.3914212 , -0.6504351 ,\n",
       "       -0.9010805 , -1.1341541 ,  0.75565654,  1.2941337 ,  0.0880572 ,\n",
       "       -1.0341461 , -0.1750075 , -0.01880708, -1.0835075 , -2.0333962 ,\n",
       "        1.1372623 ,  1.0626172 , -1.8369784 , -2.2662086 , -3.382057  ,\n",
       "        1.6751666 , -0.2988223 , -0.25563756, -1.5594274 ,  0.6313433 ,\n",
       "       -1.2667153 , -1.6857744 , -1.0949599 ,  0.7742313 , -0.6095523 ,\n",
       "        3.19503   ,  0.13200459,  1.7937473 , -2.8782516 ,  1.3821276 ,\n",
       "        2.2895143 ,  0.0741943 , -0.41046414,  1.438796  ,  0.19373988,\n",
       "        1.4294034 ,  1.5025262 ,  1.4849502 ,  1.5754777 ,  2.7793512 ,\n",
       "       -0.6885003 , -0.30154693, -1.708323  ,  1.1030879 , -2.2597387 ,\n",
       "        1.1909146 ,  2.4399316 ,  0.3990314 ,  0.904154  ,  0.5454401 ,\n",
       "       -1.3235748 , -0.64812386,  0.22390233,  0.9657619 , -0.47360668,\n",
       "       -0.10278235, -1.0679734 , -0.91414386,  0.92069   ,  0.3549338 ,\n",
       "        0.32858834,  0.84870636,  3.596926  , -1.6651102 ,  0.23658653,\n",
       "        1.0515738 ,  0.40531915, -0.773514  , -0.93460965, -0.3946274 ,\n",
       "       -1.5657727 ,  1.183652  ,  2.5277    ,  0.57700926,  1.7051374 ,\n",
       "       -1.8249958 , -2.0328498 ,  0.6617798 ,  0.85747904,  0.31782728,\n",
       "       -1.1660796 ,  0.32923874,  2.2055087 , -0.12782003,  2.0455444 ,\n",
       "       -0.1724252 ,  0.46001154,  1.559042  , -1.6152996 , -0.84242785,\n",
       "        0.7553168 ,  0.39734274,  0.07714175,  0.05610155,  0.32837135,\n",
       "        1.0220716 ,  1.3816743 ,  0.8049544 ,  0.28728685, -0.97610044,\n",
       "        0.8861181 , -0.01250968, -1.4845604 , -1.5236791 , -1.5451258 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors, Word2Vec\n",
    "word2vec_path = os.getenv('HOME')+'/aiffel/sentiment_classification/ko.bin'\n",
    "word2vec = Word2Vec.load(word2vec_path)\n",
    "vector = word2vec['사랑']\n",
    "vector     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ssac12/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similar_by_word` (Method will be removed in 4.0.0, use self.wv.similar_by_word() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('슬픔', 0.7216663360595703),\n",
       " ('행복', 0.6759077310562134),\n",
       " ('절망', 0.6468985676765442),\n",
       " ('기쁨', 0.6458414793014526),\n",
       " ('이별', 0.6334798336029053),\n",
       " ('추억', 0.6320937871932983),\n",
       " ('인생', 0.6216273307800293),\n",
       " ('애정', 0.6206068992614746),\n",
       " ('연인', 0.6186063289642334),\n",
       " ('유혹', 0.5965287685394287)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.similar_by_word(\"사랑\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 한국어 word2vec을 사용하고 나서 연관 단어가 더 잘 뜨는 것 확인 가능 \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ssac12/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  \n",
      "/home/ssac12/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 200  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 41, 200)           2000000   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 35, 16)            22416     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 7, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1, 16)             1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,024,369\n",
      "Trainable params: 2,024,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 2 Conv1D + MaxPooling\n",
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 200  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "# 모델 구성\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 100)         2000000   \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 808       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,000,817\n",
      "Trainable params: 2,000,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 3 MaxPooling\n",
    "vocab_size = 20000  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 100   # 단어 하나를 표현하는 임베딩 벡터의 차원수입니다. \n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 한국어 Word2vec 적용 후 LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 32)          640000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               82432     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 722,561\n",
      "Trainable params: 722,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 20000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 100  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "# 모델 구성\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 32))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1940/1950 [============================>.] - ETA: 0s - loss: 0.3951 - acc: 0.8226\n",
      "Epoch 00001: val_acc improved from -inf to 0.84626, saving model to best_model.h5\n",
      "1950/1950 [==============================] - 10s 5ms/step - loss: 0.3952 - acc: 0.8226 - val_loss: 0.3646 - val_acc: 0.8463\n",
      "Epoch 2/10\n",
      "1949/1950 [============================>.] - ETA: 0s - loss: 0.3306 - acc: 0.8567\n",
      "Epoch 00002: val_acc improved from 0.84626 to 0.85125, saving model to best_model.h5\n",
      "1950/1950 [==============================] - 9s 5ms/step - loss: 0.3306 - acc: 0.8567 - val_loss: 0.3451 - val_acc: 0.8513\n",
      "Epoch 3/10\n",
      "1945/1950 [============================>.] - ETA: 0s - loss: 0.3062 - acc: 0.8695\n",
      "Epoch 00003: val_acc improved from 0.85125 to 0.86445, saving model to best_model.h5\n",
      "1950/1950 [==============================] - 10s 5ms/step - loss: 0.3062 - acc: 0.8695 - val_loss: 0.3173 - val_acc: 0.8645\n",
      "Epoch 4/10\n",
      "1944/1950 [============================>.] - ETA: 0s - loss: 0.2916 - acc: 0.8771\n",
      "Epoch 00004: val_acc improved from 0.86445 to 0.86784, saving model to best_model.h5\n",
      "1950/1950 [==============================] - 9s 5ms/step - loss: 0.2917 - acc: 0.8770 - val_loss: 0.3089 - val_acc: 0.8678\n",
      "Epoch 5/10\n",
      "1943/1950 [============================>.] - ETA: 0s - loss: 0.2811 - acc: 0.8826\n",
      "Epoch 00005: val_acc did not improve from 0.86784\n",
      "1950/1950 [==============================] - 9s 5ms/step - loss: 0.2811 - acc: 0.8826 - val_loss: 0.3107 - val_acc: 0.8672\n",
      "Epoch 6/10\n",
      "1942/1950 [============================>.] - ETA: 0s - loss: 0.2723 - acc: 0.8869\n",
      "Epoch 00006: val_acc improved from 0.86784 to 0.86883, saving model to best_model.h5\n",
      "1950/1950 [==============================] - 9s 5ms/step - loss: 0.2724 - acc: 0.8868 - val_loss: 0.3050 - val_acc: 0.8688\n",
      "Epoch 7/10\n",
      "1943/1950 [============================>.] - ETA: 0s - loss: 0.2633 - acc: 0.8917\n",
      "Epoch 00007: val_acc did not improve from 0.86883\n",
      "1950/1950 [==============================] - 9s 5ms/step - loss: 0.2633 - acc: 0.8918 - val_loss: 0.3148 - val_acc: 0.8676\n",
      "Epoch 8/10\n",
      "1942/1950 [============================>.] - ETA: 0s - loss: 0.2549 - acc: 0.8954\n",
      "Epoch 00008: val_acc did not improve from 0.86883\n",
      "1950/1950 [==============================] - 9s 5ms/step - loss: 0.2548 - acc: 0.8954 - val_loss: 0.3133 - val_acc: 0.8681\n",
      "Epoch 9/10\n",
      "1939/1950 [============================>.] - ETA: 0s - loss: 0.2470 - acc: 0.8992\n",
      "Epoch 00009: val_acc improved from 0.86883 to 0.86921, saving model to best_model.h5\n",
      "1950/1950 [==============================] - 10s 5ms/step - loss: 0.2469 - acc: 0.8993 - val_loss: 0.3139 - val_acc: 0.8692\n",
      "Epoch 10/10\n",
      "1942/1950 [============================>.] - ETA: 0s - loss: 0.2386 - acc: 0.9030\n",
      "Epoch 00010: val_acc improved from 0.86921 to 0.87215, saving model to best_model.h5\n",
      "1950/1950 [==============================] - 9s 5ms/step - loss: 0.2386 - acc: 0.9030 - val_loss: 0.3074 - val_acc: 0.8721\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train, epochs=10, callbacks=[es, mc], batch_size=60, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 6. Loss, Accuracy 그래프 시각화\n",
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['acc']\n",
    "val_acc = history_dict['val_acc']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 2s - loss: 0.3099 - acc: 0.8696\n",
      "[0.3099353015422821, 0.8696218132972717]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 한국어 Word2vec을 적용하고 난 후의 LSTM 모델의 정확도는 0.8696으로 향상된것을 볼 수 있음. \n",
    "\n",
    "##### 참고 : https://wikidocs.net/44249"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
