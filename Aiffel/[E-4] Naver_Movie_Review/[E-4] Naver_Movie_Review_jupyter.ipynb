{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "패키지 목록을 읽는 중입니다... 완료0%\n",
      "E: 잠금 파일 /var/lib/apt/lists/lock 파일을 열 수 없습니다 - open (13: 허가 거부)\n",
      "E: /var/lib/apt/lists/ 디렉터리를 잠글 수 없습니다\n",
      "W: /var/cache/apt/pkgcache.bin 파일을 삭제하는데 문제가 있습니다 - RemoveCaches (13: 허가 거부)\n",
      "W: /var/cache/apt/srcpkgcache.bin 파일을 삭제하는데 문제가 있습니다 - RemoveCaches (13: 허가 거부)\n",
      "E: 잠금 파일 /var/lib/dpkg/lock-frontend 파일을 열 수 없습니다 - open (13: 허가 거부)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
      "Requirement already satisfied: konlpy in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (0.5.2)\n",
      "Requirement already satisfied: JPype1-py3 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (0.5.5.4)\n",
      "Requirement already satisfied: beautifulsoup4==4.6.0 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from konlpy) (4.6.0)\n",
      "Requirement already satisfied: numpy>=1.6 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from konlpy) (1.19.4)\n",
      "Requirement already satisfied: colorama in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from konlpy) (0.4.4)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from konlpy) (1.2.1)\n",
      "Requirement already satisfied: lxml>=4.1.0 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from konlpy) (4.6.2)\n",
      "Requirement already satisfied: tweepy>=3.7.0 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from konlpy) (3.10.0)\n",
      "Requirement already satisfied: typing-extensions in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from tweepy>=3.7.0->konlpy) (2.25.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.26.2)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
      "/bin/bash: !bash: 명령어를 찾을 수 없음\n",
      "Requirement already satisfied: pandas in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from pandas) (1.19.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from pandas) (2020.5)\n",
      "Requirement already satisfied: six>=1.5 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: Mecab in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (0.996.2)\n",
      "1\n",
      "Requirement already satisfied: Konlpy in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (0.5.2)\n",
      "Requirement already satisfied: tweepy>=3.7.0 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from Konlpy) (3.10.0)\n",
      "Requirement already satisfied: colorama in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from Konlpy) (0.4.4)\n",
      "Requirement already satisfied: beautifulsoup4==4.6.0 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from Konlpy) (4.6.0)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from Konlpy) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.6 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from Konlpy) (1.19.4)\n",
      "Requirement already satisfied: lxml>=4.1.0 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from Konlpy) (4.6.2)\n",
      "Requirement already satisfied: typing-extensions in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from JPype1>=0.7.0->Konlpy) (3.7.4.3)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from tweepy>=3.7.0->Konlpy) (1.15.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from tweepy>=3.7.0->Konlpy) (1.3.0)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from tweepy>=3.7.0->Konlpy) (2.25.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->Konlpy) (3.1.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->Konlpy) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->Konlpy) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->Konlpy) (1.26.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->Konlpy) (2020.12.5)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->Konlpy) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "# colab 에 Mecab name 'Tagger'is not defined 오류 없애기\n",
    "# 참고 : https://sosomemo.tistory.com/31\n",
    "!apt-get update\n",
    "!apt-get install g++ openjdk-8-jdk \n",
    "!pip3 install konlpy JPype1-py3\n",
    "!echo ssac1234 | !bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
    "! pip install pandas\n",
    "! pip install Mecab\n",
    "print(\"1\")\n",
    "! pip install Konlpy\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "# % matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter\n",
    "from konlpy.tag import Mecab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Mecab\n",
    "\n",
    "train_data = pd.read_table('~/aiffel/sentiment_classification/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/sentiment_classification/ratings_test.txt')\n",
    "\n",
    "tokenizer = Mecab()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "def load_data(train_data, test_data, num_words=10000):\n",
    "    # [[YOUR CODE]]\n",
    "    \n",
    "    # 데이터의 중복 제거 및 NaN 결측치 제거\n",
    "    train_data.drop_duplicates(subset = ['document'], inplace=True) \n",
    "    #subset은 중복데이터를 처리할 열을 입력, inplace는 메서드가 적용되는 원본 데이터를 변경할지 여부를 결정\n",
    "    train_data = train_data.dropna(how ='any')\n",
    "    # how = 'any' -> NA(결측치)값이 존재하면 그 행이나 열을 drop함.\n",
    "    # 참고 : https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html\n",
    "    test_data.drop_duplicates(subset = ['document'], inplace=True) \n",
    "    test_data = test_data.dropna(how ='any')\n",
    "    \n",
    "    # 한국어 토크나이저로 토큰화 및 불용어 제거\n",
    "    X_train = []\n",
    "    for sentence in train_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence)\n",
    "        # Mecab의 morphs 기능을 통해 형태소로 구문분석\n",
    "        # 참고 : https://konlpy-ko.readthedocs.io/ko/v0.4.3/api/konlpy.tag/\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] \n",
    "        # 구분한 형태소 중 stopwords에 존재하지 않는 것만 temp_X에 저장\n",
    "        X_train.append(temp_X)\n",
    "    print(\"Xtrain\",X_train)\n",
    "        \n",
    "    X_test = []\n",
    "    for sentence in test_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence)\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] \n",
    "        X_test.append(temp_X)\n",
    "    \n",
    "    #?? concatenate는 배열을 붙이는 거라는 데 하나로 어떻게 합치지?\n",
    "    # ndarray클래스이 tolist() 메소드를 이용해 list 객체를 구하여 words에 저장.\n",
    "    words = np.concatenate(X_train).tolist() \n",
    "    # 리스트의 나온 횟수만큼 counter 리스트에 저장\n",
    "    counter = Counter(words)\n",
    "    # 데이터 개수가 많은 순으로 정렬된 배열을  리턴하는 most_common사용\n",
    "    # 참고 : https://www.daleseo.com/python-collections-counter/\n",
    "    counter = counter.most_common(10000-4)\n",
    "    #사전에 정의되 있던 인덱스 + 문자열에서 추출한 문자를 \n",
    "    vocab = ['<PAD>', '<BOS>', '<UNK>', '<UNUSED>'] + [key for key, _ in counter]\n",
    "    \n",
    "    # 리스트 컨프리헨션 사용헤서 사전 word_to_index구성\n",
    "    # 참고 : https://wikidocs.net/16045\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "\n",
    "    \n",
    "    def wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in wordlist]\n",
    "\n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
    "\n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index\n",
    "  \n",
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 모델 구성을 위한 데이터 분석 및 가공\n",
    "total_data_text = list(X_train) + list(X_test)\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "#print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "#print('문장길이 최대 : ', np.max(num_tokens))\n",
    "#print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "#print('pad_sequences maxlen : ', maxlen)\n",
    "#print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 모델 구성 및 validation set 구성\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(X_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='post', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(X_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='post', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "# print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136182, 41)\n",
      "(136182,)\n",
      "Epoch 1/10\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.5522 - accuracy: 0.6989 - val_loss: 0.3871 - val_accuracy: 0.8391\n",
      "Epoch 2/10\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.3533 - accuracy: 0.8534 - val_loss: 0.3518 - val_accuracy: 0.8496\n",
      "Epoch 3/10\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.3246 - accuracy: 0.8648 - val_loss: 0.3424 - val_accuracy: 0.8522\n",
      "Epoch 4/10\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.3109 - accuracy: 0.8710 - val_loss: 0.3441 - val_accuracy: 0.8489\n",
      "Epoch 5/10\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.3024 - accuracy: 0.8742 - val_loss: 0.3429 - val_accuracy: 0.8507\n",
      "Epoch 6/10\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.2961 - accuracy: 0.8764 - val_loss: 0.3572 - val_accuracy: 0.8449\n",
      "Epoch 7/10\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.2871 - accuracy: 0.8797 - val_loss: 0.3476 - val_accuracy: 0.8517\n",
      "Epoch 8/10\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.2776 - accuracy: 0.8827 - val_loss: 0.3571 - val_accuracy: 0.8477\n",
      "Epoch 9/10\n",
      "266/266 [==============================] - 4s 13ms/step - loss: 0.2689 - accuracy: 0.8854 - val_loss: 0.3690 - val_accuracy: 0.8486\n",
      "Epoch 10/10\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.2610 - accuracy: 0.8872 - val_loss: 0.3741 - val_accuracy: 0.8455\n",
      "1537/1537 - 3s - loss: 0.3797 - accuracy: 0.8443\n",
      "[0.3797006905078888, 0.8442947864532471]\n"
     ]
    }
   ],
   "source": [
    "# 5. 모델 훈련 개시\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계 - 딥러닝 모델 코드를 직접 작성해 주세요.\n",
    "model = keras.Sequential()\n",
    "# [[YOUR CODE]]\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.LSTM(8))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "# model.summary()\n",
    "# validation set 10000건 분리\n",
    "x_val = x_train[:10000]\n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_x_train = x_train[10000:]\n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "epochs = 10  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다.\n",
    "\n",
    "history = model.fit(partial_x_train, partial_y_train, epochs=epochs,\n",
    "                    batch_size=512, validation_data=(x_val, y_val), verbose=1)\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 6. Loss, Accuracy 그래프 시각화\n",
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (3.8.3)\n",
      "Requirement already satisfied: six>=1.5.0 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from gensim) (4.1.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/ssac12/anaconda3/envs/aiffel/lib/python3.7/site-packages (from gensim) (1.19.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.07421875e-01, -2.01171875e-01,  1.23046875e-01,  2.11914062e-01,\n",
       "       -9.13085938e-02,  2.16796875e-01, -1.31835938e-01,  8.30078125e-02,\n",
       "        2.02148438e-01,  4.78515625e-02,  3.66210938e-02, -2.45361328e-02,\n",
       "        2.39257812e-02, -1.60156250e-01, -2.61230469e-02,  9.71679688e-02,\n",
       "       -6.34765625e-02,  1.84570312e-01,  1.70898438e-01, -1.63085938e-01,\n",
       "       -1.09375000e-01,  1.49414062e-01, -4.65393066e-04,  9.61914062e-02,\n",
       "        1.68945312e-01,  2.60925293e-03,  8.93554688e-02,  6.49414062e-02,\n",
       "        3.56445312e-02, -6.93359375e-02, -1.46484375e-01, -1.21093750e-01,\n",
       "       -2.27539062e-01,  2.45361328e-02, -1.24511719e-01, -3.18359375e-01,\n",
       "       -2.20703125e-01,  1.30859375e-01,  3.66210938e-02, -3.63769531e-02,\n",
       "       -1.13281250e-01,  1.95312500e-01,  9.76562500e-02,  1.26953125e-01,\n",
       "        6.59179688e-02,  6.93359375e-02,  1.02539062e-02,  1.75781250e-01,\n",
       "       -1.68945312e-01,  1.21307373e-03, -2.98828125e-01, -1.15234375e-01,\n",
       "        5.66406250e-02, -1.77734375e-01, -2.08984375e-01,  1.76757812e-01,\n",
       "        2.38037109e-02, -2.57812500e-01, -4.46777344e-02,  1.88476562e-01,\n",
       "        5.51757812e-02,  5.02929688e-02, -1.06933594e-01,  1.89453125e-01,\n",
       "       -1.16210938e-01,  8.49609375e-02, -1.71875000e-01,  2.45117188e-01,\n",
       "       -1.73828125e-01, -8.30078125e-03,  4.56542969e-02, -1.61132812e-02,\n",
       "        1.86523438e-01, -6.05468750e-02, -4.17480469e-02,  1.82617188e-01,\n",
       "        2.20703125e-01, -1.22558594e-01, -2.55126953e-02, -3.08593750e-01,\n",
       "        9.13085938e-02,  1.60156250e-01,  1.70898438e-01,  1.19628906e-01,\n",
       "        7.08007812e-02, -2.64892578e-02, -3.08837891e-02,  4.06250000e-01,\n",
       "       -1.01562500e-01,  5.71289062e-02, -7.26318359e-03, -9.17968750e-02,\n",
       "       -1.50390625e-01, -2.55859375e-01,  2.16796875e-01, -3.63769531e-02,\n",
       "        2.24609375e-01,  8.00781250e-02,  1.56250000e-01,  5.27343750e-02,\n",
       "        1.50390625e-01, -1.14746094e-01, -8.64257812e-02,  1.19140625e-01,\n",
       "       -7.17773438e-02,  2.73437500e-01, -1.64062500e-01,  7.29370117e-03,\n",
       "        4.21875000e-01, -1.12792969e-01, -1.35742188e-01, -1.31835938e-01,\n",
       "       -1.37695312e-01, -7.66601562e-02,  6.25000000e-02,  4.98046875e-02,\n",
       "       -1.91406250e-01, -6.03027344e-02,  2.27539062e-01,  5.88378906e-02,\n",
       "       -3.24218750e-01,  5.41992188e-02, -1.35742188e-01,  8.17871094e-03,\n",
       "       -5.24902344e-02, -1.74713135e-03, -9.81445312e-02, -2.86865234e-02,\n",
       "        3.61328125e-02,  2.15820312e-01,  5.98144531e-02, -3.08593750e-01,\n",
       "       -2.27539062e-01,  2.61718750e-01,  9.86328125e-02, -5.07812500e-02,\n",
       "        1.78222656e-02,  1.31835938e-01, -5.35156250e-01, -1.81640625e-01,\n",
       "        1.38671875e-01, -3.10546875e-01, -9.71679688e-02,  1.31835938e-01,\n",
       "       -1.16210938e-01,  7.03125000e-02,  2.85156250e-01,  3.51562500e-02,\n",
       "       -1.01562500e-01, -3.75976562e-02,  1.41601562e-01,  1.42578125e-01,\n",
       "       -5.68847656e-02,  2.65625000e-01, -2.09960938e-01,  9.64355469e-03,\n",
       "       -6.68945312e-02, -4.83398438e-02, -6.10351562e-02,  2.45117188e-01,\n",
       "       -9.66796875e-02,  1.78222656e-02, -1.27929688e-01, -4.78515625e-02,\n",
       "       -7.26318359e-03,  1.79687500e-01,  2.78320312e-02, -2.10937500e-01,\n",
       "       -1.43554688e-01, -1.27929688e-01,  1.73339844e-02, -3.60107422e-03,\n",
       "       -2.04101562e-01,  3.63159180e-03, -1.19628906e-01, -6.15234375e-02,\n",
       "        5.93261719e-02, -3.23486328e-03, -1.70898438e-01, -3.14941406e-02,\n",
       "       -8.88671875e-02, -2.89062500e-01,  3.44238281e-02, -1.87500000e-01,\n",
       "        2.94921875e-01,  1.58203125e-01, -1.19628906e-01,  7.61718750e-02,\n",
       "        6.39648438e-02, -4.68750000e-02, -6.83593750e-02,  1.21459961e-02,\n",
       "       -1.44531250e-01,  4.54101562e-02,  3.68652344e-02,  3.88671875e-01,\n",
       "        1.45507812e-01, -2.55859375e-01, -4.46777344e-02, -1.33789062e-01,\n",
       "       -1.38671875e-01,  6.59179688e-02,  1.37695312e-01,  1.14746094e-01,\n",
       "        2.03125000e-01, -4.78515625e-02,  1.80664062e-02, -8.54492188e-02,\n",
       "       -2.48046875e-01, -3.39843750e-01, -2.83203125e-02,  1.05468750e-01,\n",
       "       -2.14843750e-01, -8.74023438e-02,  7.12890625e-02,  1.87500000e-01,\n",
       "       -1.12304688e-01,  2.73437500e-01, -3.26171875e-01, -1.77734375e-01,\n",
       "       -4.24804688e-02, -2.69531250e-01,  6.64062500e-02, -6.88476562e-02,\n",
       "       -1.99218750e-01, -7.03125000e-02, -2.43164062e-01, -3.66210938e-02,\n",
       "       -7.37304688e-02, -1.77734375e-01,  9.17968750e-02, -1.25000000e-01,\n",
       "       -1.65039062e-01, -3.57421875e-01, -2.85156250e-01, -1.66992188e-01,\n",
       "        1.97265625e-01, -1.53320312e-01,  2.31933594e-02,  2.06054688e-01,\n",
       "        1.80664062e-01, -2.74658203e-02, -1.92382812e-01, -9.61914062e-02,\n",
       "       -1.06811523e-02, -4.73632812e-02,  6.54296875e-02, -1.25732422e-02,\n",
       "        1.78222656e-02, -8.00781250e-02, -2.59765625e-01,  9.37500000e-02,\n",
       "       -7.81250000e-02,  4.68750000e-02, -2.22167969e-02,  1.86767578e-02,\n",
       "        3.11279297e-02,  1.04980469e-02, -1.69921875e-01,  2.58789062e-02,\n",
       "       -3.41796875e-02, -1.44042969e-02, -5.46875000e-02, -8.78906250e-02,\n",
       "        1.96838379e-03,  2.23632812e-01, -1.36718750e-01,  1.75781250e-01,\n",
       "       -1.63085938e-01,  1.87500000e-01,  3.44238281e-02, -5.63964844e-02,\n",
       "       -2.27689743e-05,  4.27246094e-02,  5.81054688e-02, -1.07910156e-01,\n",
       "       -3.88183594e-02, -2.69531250e-01,  3.34472656e-02,  9.81445312e-02,\n",
       "        5.63964844e-02,  2.23632812e-01, -5.49316406e-02,  1.46484375e-01,\n",
       "        5.93261719e-02, -2.19726562e-01,  6.39648438e-02,  1.66015625e-02,\n",
       "        4.56542969e-02,  3.26171875e-01, -3.80859375e-01,  1.70898438e-01,\n",
       "        5.66406250e-02, -1.04492188e-01,  1.38671875e-01, -1.57226562e-01,\n",
       "        3.23486328e-03, -4.80957031e-02, -2.48046875e-01, -6.20117188e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "word2vec_path = os.getenv('HOME')+'/aiffel/sentiment_classification/GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True, limit=1000000)\n",
    "vector = word2vec['computer']\n",
    "vector     # 무려 300dim의 워드 벡터입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 41, 300)           3000000   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 35, 16)            33616     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 7, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1, 16)             1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,035,569\n",
      "Trainable params: 3,035,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "# 모델 구성\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "266/266 [==============================] - 21s 80ms/step - loss: 0.6133 - accuracy: 0.6333 - val_loss: 0.4319 - val_accuracy: 0.8041\n",
      "Epoch 2/10\n",
      "266/266 [==============================] - 21s 80ms/step - loss: 0.3831 - accuracy: 0.8315 - val_loss: 0.3651 - val_accuracy: 0.8409\n",
      "Epoch 3/10\n",
      "266/266 [==============================] - 20s 77ms/step - loss: 0.3351 - accuracy: 0.8569 - val_loss: 0.3470 - val_accuracy: 0.8491\n",
      "Epoch 4/10\n",
      "266/266 [==============================] - 20s 74ms/step - loss: 0.3137 - accuracy: 0.8680 - val_loss: 0.3517 - val_accuracy: 0.8484\n",
      "Epoch 5/10\n",
      "266/266 [==============================] - 20s 74ms/step - loss: 0.2938 - accuracy: 0.8778 - val_loss: 0.3552 - val_accuracy: 0.8456\n",
      "Epoch 6/10\n",
      "266/266 [==============================] - 20s 74ms/step - loss: 0.2756 - accuracy: 0.8874 - val_loss: 0.3559 - val_accuracy: 0.8470\n",
      "Epoch 7/10\n",
      "266/266 [==============================] - 20s 74ms/step - loss: 0.2595 - accuracy: 0.8951 - val_loss: 0.3624 - val_accuracy: 0.8443\n",
      "Epoch 8/10\n",
      "266/266 [==============================] - 20s 74ms/step - loss: 0.2366 - accuracy: 0.9072 - val_loss: 0.3782 - val_accuracy: 0.8414\n",
      "Epoch 9/10\n",
      "266/266 [==============================] - 20s 74ms/step - loss: 0.2222 - accuracy: 0.9137 - val_loss: 0.3842 - val_accuracy: 0.8409\n",
      "Epoch 10/10\n",
      "266/266 [==============================] - 20s 74ms/step - loss: 0.1938 - accuracy: 0.9269 - val_loss: 0.4056 - val_accuracy: 0.8423\n"
     ]
    }
   ],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=10  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 2s - loss: 0.4187 - accuracy: 0.8365\n",
      "[0.41874992847442627, 0.8365441560745239]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
