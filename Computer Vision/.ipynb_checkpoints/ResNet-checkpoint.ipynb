{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef build_ResNet_block(input_layer,\\n                    num_cnn=3, \\n                    channel=64,\\n                    block_num=1,\\n                   ):\\n    # 입력 레이어\\n    #x = keras.layers.ZeroPadding2D(padding=(3, 3))(input_layer)\\n    x = keras.layers.Conv2D(64, (7, 7), strides=(2, 2))(input_layer)\\n    x = keras.layers.BatchNormalization()(x)\\n    x = keras.layers.Activation('relu')(x)\\n    #x = keras.layers.ZeroPadding2D(padding=(1,1))(x)\\n    # Max Pooling 레이어\\n    x = keras.layers.MaxPooling2D(\\n        pool_size=(2, 2),\\n        strides=2,\\n        name=f'block{block_num}_pooling'\\n    )(x)\\n    \\n    # CNN 레이어\\n    for cnn_num in range(num_cnn):\\n        x = keras.layers.Conv2D(\\n            filters=channel,\\n            kernel_size=(3,3),\\n            activation='relu',\\n            kernel_initializer='he_normal',\\n            padding='same',\\n            name=f'block{block_num}_conv{cnn_num}'\\n        )(x)    \\n        \\n    x = keras.layers.BatchNormalization(axis = 3)(x)\\n    \\n    \\n\\n    \\n    return x\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function for building VResNet Block\n",
    "def build_ResNet_block(input_layer ,num_cnn=2,stage_num=2, channel=64, is_50=False):\n",
    "    x = input_layer\n",
    "    short = x\n",
    "    if not is_50:\n",
    "        for cnn_num in range(num_cnn):\n",
    "            if cnn_num == 0:\n",
    "                if stage_num == 2:\n",
    "                    stride = 1\n",
    "                else:\n",
    "                    stride = 2\n",
    "                    \n",
    "                x = keras.layers.Conv2D(filters=channel,\n",
    "                                        kernel_size=(3, 3),\n",
    "                                        padding='same',\n",
    "                                        strides=stride,\n",
    "                                        name=f'stage{stage_num}_{cnn_num+1}_conv1',\n",
    "                                        )(x)\n",
    "                x = keras.layers.BatchNormalization(name=f'stage{stage_num}_{cnn_num+1}_bn1')(x)\n",
    "                x = keras.layers.Activation('relu')(x)\n",
    "                x = keras.layers.Conv2D(filters=channel,\n",
    "                                        kernel_size=(3, 3),\n",
    "                                        padding='same',\n",
    "                                        name=f'stage{stage_num}_{cnn_num+1}_conv2',\n",
    "                                        )(x)\n",
    "                x = keras.layers.BatchNormalization(name=f'stage{stage_num}_{cnn_num+1}_bn2')(x)                    \n",
    "                x = keras.layers.Activation('relu')(x)\n",
    "                short = x\n",
    "                \n",
    "            else:\n",
    "                x = keras.layers.Conv2D(filters=channel,\n",
    "                                        kernel_size=(3, 3),\n",
    "                                        padding='same',\n",
    "                                        name=f'stage{stage_num}_{cnn_num+1}_conv1',\n",
    "                                        )(x)\n",
    "                x = keras.layers.BatchNormalization(name=f'stage{stage_num}_{cnn_num+1}_bn1')(x)\n",
    "                x = keras.layers.Activation('relu')(x)\n",
    "                x = keras.layers.Conv2D(filters=channel,\n",
    "                                        kernel_size=(3, 3),\n",
    "                                        padding='same',\n",
    "                                        name=f'stage{stage_num}_{cnn_num+1}_conv2',\n",
    "                                        )(x)\n",
    "                x = keras.layers.BatchNormalization(name=f'stage{stage_num}_{cnn_num+1}_bn2')(x)\n",
    "\n",
    "    else:\n",
    "        for cnn_num in range(num_cnn):\n",
    "            if cnn_num == 0:\n",
    "                if stage_num == 2:\n",
    "                    stride = 1\n",
    "                else:\n",
    "                    stride = 2\n",
    "                x = keras.layers.Conv2D(filters=channel,\n",
    "                                        kernel_size=(1, 1),\n",
    "                                        strides = stride,\n",
    "                                        padding='same',\n",
    "                                        name=f'stage{stage_num}_{cnn_num+1}_conv1',\n",
    "                                       )(x)\n",
    "                x = keras.layers.BatchNormalization(name=f'stage{stage_num}_{cnn_num+1}_bn1')(x)\n",
    "                x = keras.layers.Activation('relu')(x)\n",
    "                x = keras.layers.Conv2D(filters=channel,\n",
    "                                        kernel_size=(3, 3),\n",
    "                                        padding='same',\n",
    "                                        name=f'stage{stage_num}_{cnn_num+1}_conv2',\n",
    "                                       )(x)\n",
    "                x = keras.layers.BatchNormalization(name=f'stae{stage_num}_{cnn_num+1}_bn2')(x)\n",
    "                x = keras.layers.Activation('relu')(x)\n",
    "                x = keras.layers.Conv2D(filters=channel*4,\n",
    "                                        kernel_size=(1, 1),\n",
    "                                        padding='same',\n",
    "                                        name=f'stage{stage_num}_{cnn_num+1}_conv3',\n",
    "                                       )(x)\n",
    "                x = keras.layers.BatchNormalization(name=f'stage{stage_num}_{cnn_num+1}_bn3')(x)\n",
    "                if is_plain == False:\n",
    "                    short = keras.layers.Conv2D(filters=channel*4,\n",
    "                                                kernel_size=(1, 1),\n",
    "                                                strides=stride,\n",
    "                                                padding='same',\n",
    "                                                name=f'stage{stage_num}_{cnn_num+1}_short',\n",
    "                                                )(short)\n",
    "                    short = keras.layers.BatchNormalization(name=f'stage{stage_num}_{cnn_num+1}_bn4')(short)\n",
    "                    x = keras.layers.Add()([x, short])\n",
    "                x = keras.layers.Activation('relu')(x)\n",
    "                short = x\n",
    "            else:\n",
    "                x = keras.layers.Conv2D(filters=channel,\n",
    "                                        kernel_size=(1, 1),\n",
    "                                        padding='same',\n",
    "                                        name=f'stage{stage_num}_{cnn_num+1}_conv1',\n",
    "                                       )(x)\n",
    "                x = keras.layers.BatchNormalization(name=f'stage{stage_num}_{cnn_num+1}_bn1')(x)\n",
    "                x = keras.layers.Activation('relu')(x)\n",
    "                x = keras.layers.Conv2D(filters=channel,\n",
    "                                        kernel_size=(3, 3),\n",
    "                                        padding='same',\n",
    "                                        name=f'stage{stage_num}_{cnn_num+1}_conv2',\n",
    "                                       )(x)\n",
    "                x = keras.layers.BatchNormalization(name=f'stae{stage_num}_{cnn_num+1}_bn2')(x)\n",
    "                x = keras.layers.Activation('relu')(x)\n",
    "                x = keras.layers.Conv2D(filters=channel*4,\n",
    "                                        kernel_size=(1, 1),\n",
    "                                        padding='same',\n",
    "                                        name=f'stage{stage_num}_{cnn_num+1}_conv3',\n",
    "                                       )(x)\n",
    "                x = keras.layers.BatchNormalization(name=f'stage{stage_num}_{cnn_num+1}_bn3')(x)\n",
    "                if is_plain == False:\n",
    "                    x = keras.layers.Add()([x, short])\n",
    "                x = keras.layers.Activation('relu')(x)\n",
    "                short = x\n",
    "    return x\n",
    "'''\n",
    "def build_ResNet_block(input_layer,\n",
    "                    num_cnn=3, \n",
    "                    channel=64,\n",
    "                    block_num=1,\n",
    "                   ):\n",
    "    # 입력 레이어\n",
    "    #x = keras.layers.ZeroPadding2D(padding=(3, 3))(input_layer)\n",
    "    x = keras.layers.Conv2D(64, (7, 7), strides=(2, 2))(input_layer)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    #x = keras.layers.ZeroPadding2D(padding=(1,1))(x)\n",
    "    # Max Pooling 레이어\n",
    "    x = keras.layers.MaxPooling2D(\n",
    "        pool_size=(2, 2),\n",
    "        strides=2,\n",
    "        name=f'block{block_num}_pooling'\n",
    "    )(x)\n",
    "    \n",
    "    # CNN 레이어\n",
    "    for cnn_num in range(num_cnn):\n",
    "        x = keras.layers.Conv2D(\n",
    "            filters=channel,\n",
    "            kernel_size=(3,3),\n",
    "            activation='relu',\n",
    "            kernel_initializer='he_normal',\n",
    "            padding='same',\n",
    "            name=f'block{block_num}_conv{cnn_num}'\n",
    "        )(x)    \n",
    "        \n",
    "    x = keras.layers.BatchNormalization(axis = 3)(x)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    return x\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet_input_layer = keras.layers.Input(shape=(32,32,3))   # 입력 레이어 생성\n",
    "ResNet_block_output = build_ResNet_block(ResNet_input_layer)    # VGG 블록 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "stage2_1_conv1 (Conv2D)      (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "stage2_1_bn1 (BatchNormaliza (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "stage2_1_conv2 (Conv2D)      (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "stage2_1_bn2 (BatchNormaliza (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "stage2_2_conv1 (Conv2D)      (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "stage2_2_bn1 (BatchNormaliza (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "stage2_2_conv2 (Conv2D)      (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "stage2_2_bn2 (BatchNormaliza (None, 32, 32, 64)        256       \n",
      "=================================================================\n",
      "Total params: 113,600\n",
      "Trainable params: 113,088\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 블록 1개짜리 model 생성\n",
    "model = keras.Model(inputs=ResNet_input_layer, outputs=ResNet_block_output)  \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet - 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef build_resnet(input_shape=(32,32,3),\\n              num_cnn_list=[3,4,6,3],\\n              channel_list=[64,128,256,512],\\n              num_classes=10,\\n              is_50 = False):\\n    \\n    assert len(num_cnn_list) == len(channel_list) #모델을 만들기 전에 config list들이 같은 길이인지 확인합니다.\\n    \\n    input_layer = keras.layers.Input(shape=input_shape)  # input layer를 만들어둡니다.\\n    output = input_layer\\n    \\n    # config list들의 길이만큼 반복해서 블록을 생성합니다.\\n    for i, (num_cnn, channel) in enumerate(zip(num_cnn_list, channel_list)):\\n        output = build_ResNet_block(\\n            output,\\n            X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\\n            num_cnn=num_cnn, \\n            channel=channel,\\n            block_num=i\\n        )\\n        \\n    output = keras.layers.Flatten(name='flatten')(output)\\n    output = keras.layers.Dense(4096, activation='relu', name='fc1')(output)\\n    output = keras.layers.Dense(4096, activation='relu', name='fc2')(output)\\n    output = keras.layers.Dense(num_classes, activation='softmax', name='predictions')(output)\\n    \\n    model = keras.Model(\\n        inputs=input_layer, \\n        outputs=output\\n    )\\n    return model\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VGG 모델 자체를 생성하는 함수입니다.\n",
    "def build_resnet(input_shape=(224, 224, 3), is_50=False):\n",
    "    num_cnn_ls = [3, 4, 6, 3]\n",
    "    channel_ls = [64, 128, 256, 512]\n",
    "    num_classes = 2\n",
    "    \n",
    "    input_layer = keras.layers.Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "    x = keras.layers.Conv2D(filters = 64,\n",
    "                            kernel_size=(7, 7),\n",
    "                            strides=2,\n",
    "                            kernel_initializer='he_normal',\n",
    "                            padding='same',\n",
    "                            name=f'conv2d_0',\n",
    "                            )(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x) \n",
    "    x = keras.layers.MaxPool2D(pool_size=(3,3), strides=2, padding='same', name=f'stage2_0_maxpooling')(x) \n",
    "    output = x\n",
    "    \n",
    "    for i, (num_cnn, channel) in enumerate(zip(num_cnn_ls, channel_ls)):\n",
    "        output = build_ResNet_block(output,\n",
    "                                    num_cnn=num_cnn,\n",
    "                                    stage_num = i+2,\n",
    "                                    channel=channel,\n",
    "                                    is_50 = is_50\n",
    "                                )\n",
    "        \n",
    "    output = keras.layers.Activation('relu')(output)\n",
    "    output = keras.layers.AveragePooling2D(pool_size = 1,\n",
    "                                           padding='same',\n",
    "                                           name='avg_pool')(output)\n",
    "    output = keras.layers.Flatten(name='flatten_6')(output)\n",
    "    output = keras.layers.Dense(num_classes, activation='softmax',name='predictions')(output)\n",
    "    model = keras.Model(inputs=input_layer, outputs=output)\n",
    "    return model\n",
    "'''\n",
    "def build_resnet(input_shape=(32,32,3),\n",
    "              num_cnn_list=[3,4,6,3],\n",
    "              channel_list=[64,128,256,512],\n",
    "              num_classes=10,\n",
    "              is_50 = False):\n",
    "    \n",
    "    assert len(num_cnn_list) == len(channel_list) #모델을 만들기 전에 config list들이 같은 길이인지 확인합니다.\n",
    "    \n",
    "    input_layer = keras.layers.Input(shape=input_shape)  # input layer를 만들어둡니다.\n",
    "    output = input_layer\n",
    "    \n",
    "    # config list들의 길이만큼 반복해서 블록을 생성합니다.\n",
    "    for i, (num_cnn, channel) in enumerate(zip(num_cnn_list, channel_list)):\n",
    "        output = build_ResNet_block(\n",
    "            output,\n",
    "            X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "            num_cnn=num_cnn, \n",
    "            channel=channel,\n",
    "            block_num=i\n",
    "        )\n",
    "        \n",
    "    output = keras.layers.Flatten(name='flatten')(output)\n",
    "    output = keras.layers.Dense(4096, activation='relu', name='fc1')(output)\n",
    "    output = keras.layers.Dense(4096, activation='relu', name='fc2')(output)\n",
    "    output = keras.layers.Dense(num_classes, activation='softmax', name='predictions')(output)\n",
    "    \n",
    "    model = keras.Model(\n",
    "        inputs=input_layer, \n",
    "        outputs=output\n",
    "    )\n",
    "    return model\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_0 (Conv2D)            (None, 16, 16, 64)        9472      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "stage2_0_maxpooling (MaxPool (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "stage2_1_conv1 (Conv2D)      (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "stage2_1_bn1 (BatchNormaliza (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "stage2_1_conv2 (Conv2D)      (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "stage2_1_bn2 (BatchNormaliza (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "stage2_2_conv1 (Conv2D)      (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "stage2_2_bn1 (BatchNormaliza (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "stage2_2_conv2 (Conv2D)      (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "stage2_2_bn2 (BatchNormaliza (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "stage2_3_conv1 (Conv2D)      (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "stage2_3_bn1 (BatchNormaliza (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "stage2_3_conv2 (Conv2D)      (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "stage2_3_bn2 (BatchNormaliza (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "stage3_1_conv1 (Conv2D)      (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "stage3_1_bn1 (BatchNormaliza (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "stage3_1_conv2 (Conv2D)      (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "stage3_1_bn2 (BatchNormaliza (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "stage3_2_conv1 (Conv2D)      (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "stage3_2_bn1 (BatchNormaliza (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "stage3_2_conv2 (Conv2D)      (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "stage3_2_bn2 (BatchNormaliza (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "stage3_3_conv1 (Conv2D)      (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "stage3_3_bn1 (BatchNormaliza (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "stage3_3_conv2 (Conv2D)      (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "stage3_3_bn2 (BatchNormaliza (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "stage3_4_conv1 (Conv2D)      (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "stage3_4_bn1 (BatchNormaliza (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "stage3_4_conv2 (Conv2D)      (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "stage3_4_bn2 (BatchNormaliza (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "stage4_1_conv1 (Conv2D)      (None, 2, 2, 256)         295168    \n",
      "_________________________________________________________________\n",
      "stage4_1_bn1 (BatchNormaliza (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "stage4_1_conv2 (Conv2D)      (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "stage4_1_bn2 (BatchNormaliza (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "stage4_2_conv1 (Conv2D)      (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "stage4_2_bn1 (BatchNormaliza (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "stage4_2_conv2 (Conv2D)      (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "stage4_2_bn2 (BatchNormaliza (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "stage4_3_conv1 (Conv2D)      (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "stage4_3_bn1 (BatchNormaliza (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "stage4_3_conv2 (Conv2D)      (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "stage4_3_bn2 (BatchNormaliza (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "stage4_4_conv1 (Conv2D)      (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "stage4_4_bn1 (BatchNormaliza (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "stage4_4_conv2 (Conv2D)      (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "stage4_4_bn2 (BatchNormaliza (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "stage4_5_conv1 (Conv2D)      (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "stage4_5_bn1 (BatchNormaliza (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "stage4_5_conv2 (Conv2D)      (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "stage4_5_bn2 (BatchNormaliza (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "stage4_6_conv1 (Conv2D)      (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "stage4_6_bn1 (BatchNormaliza (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "stage4_6_conv2 (Conv2D)      (None, 2, 2, 256)         590080    \n",
      "_________________________________________________________________\n",
      "stage4_6_bn2 (BatchNormaliza (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "stage5_1_conv1 (Conv2D)      (None, 1, 1, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "stage5_1_bn1 (BatchNormaliza (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "stage5_1_conv2 (Conv2D)      (None, 1, 1, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "stage5_1_bn2 (BatchNormaliza (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "stage5_2_conv1 (Conv2D)      (None, 1, 1, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "stage5_2_bn1 (BatchNormaliza (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "stage5_2_conv2 (Conv2D)      (None, 1, 1, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "stage5_2_bn2 (BatchNormaliza (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "stage5_3_conv1 (Conv2D)      (None, 1, 1, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "stage5_3_bn1 (BatchNormaliza (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "stage5_3_conv2 (Conv2D)      (None, 1, 1, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "stage5_3_bn2 (BatchNormaliza (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "avg_pool (AveragePooling2D)  (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 21,134,722\n",
      "Trainable params: 21,119,490\n",
      "Non-trainable params: 15,232\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet_34 = build_resnet(input_shape=(32, 32,3), is_50=False)\n",
    "resnet_34.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'os' has no attribute 'errno'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\bk\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format)\u001b[0m\n\u001b[0;32m   1872\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1873\u001b[1;33m             p = subprocess.Popen(\n\u001b[0m\u001b[0;32m   1874\u001b[0m                 \u001b[0mcmdline\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bk\\appdata\\local\\programs\\python\\python38\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[0;32m    853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 854\u001b[1;33m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[0;32m    855\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bk\\appdata\\local\\programs\\python\\python38\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1306\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1307\u001b[1;33m                 hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n\u001b[0m\u001b[0;32m   1308\u001b[0m                                          \u001b[1;31m# no special security\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] 지정된 파일을 찾을 수 없습니다",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-127a199b51b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresnet_34\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"resnet_34.png\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\bk\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[1;34m(model, to_file, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, dpi)\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[0mThis\u001b[0m \u001b[0menables\u001b[0m \u001b[1;32min\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mline\u001b[0m \u001b[0mdisplay\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mplots\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnotebooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m   \"\"\"\n\u001b[1;32m--> 324\u001b[1;33m   dot = model_to_dot(\n\u001b[0m\u001b[0;32m    325\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m       \u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bk\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, dpi, subgraph)\u001b[0m\n\u001b[0;32m    103\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m     message = (\n\u001b[0;32m    107\u001b[0m         \u001b[1;34m'Failed to import pydot. You must `pip install pydot` '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bk\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mcheck_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;31m# Attempt to create an image of a blank graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvocationException\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bk\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format)\u001b[0m\n\u001b[0;32m   1878\u001b[0m                 stderr=subprocess.PIPE, stdout=subprocess.PIPE)\n\u001b[0;32m   1879\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1880\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1881\u001b[0m                 raise Exception(\n\u001b[0;32m   1882\u001b[0m                     '\"{prog}\" not found in path.'.format(\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'os' has no attribute 'errno'"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(resnet_34, \"resnet_34.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "build_plaingnet()을 만들기 위한 백업 코드\n",
    "'''\n",
    "# function for building VResNet Block\n",
    "def build_ResNet_block(input_layer ,num_cnn=2,stage_num=2, channel=64, is_50=False, is_plain=True):\n",
    "    x = input_layer\n",
    "    short = x\n",
    "    if not is_50:\n",
    "        for cnn_num in range(num_cnn):\n",
    "            if cnn_num == 0:\n",
    "                if stage_num == 2:\n",
    "                    stride = 1\n",
    "                else:\n",
    "                    stride = 2\n",
    "                    \n",
    "                x = keras.layers.Conv2D(filters=channel,\n",
    "                                        kernel_size=(3, 3),\n",
    "                                        padding='same',\n",
    "                                        strides=stride,\n",
    "                                        name=f'stage{stage_num}_{cnn_num+1}_conv1',\n",
    "                                        )(x)\n",
    "                x = keras.layers.BatchNormalization(name=f'stage{stage_num}_{cnn_num+1}_bn1')(x)\n",
    "                x = keras.layers.Activation('relu')(x)\n",
    "                x = keras.layers.Conv2D(filters=channel,\n",
    "                                        kernel_size=(3, 3),\n",
    "                                        padding='same',\n",
    "                                        name=f'stage{stage_num}_{cnn_num+1}_conv2',\n",
    "                                        )(x)\n",
    "                x = keras.layers.BatchNormalization(name=f'stage{stage_num}_{cnn_num+1}_bn2')(x)\n",
    "                \n",
    "                if is_plain == False:\n",
    "                    short = keras.layers.Conv2D(filters=channel,\n",
    "                                                kernel_size=(1, 1),\n",
    "                                                strides=stride,\n",
    "                                                padding='same',\n",
    "                                                name=f'stage{stage_num}_{cnn_num+1}_short',\n",
    "                                                )(short)\n",
    "                    short = keras.layers.BatchNormalization(name=f'stage{stage_num}_{cnn_num+1}_bn3')(short)\n",
    "                    x = keras.layers.Add()([x, short])\n",
    "                    \n",
    "                x = keras.layers.Activation('relu')(x)\n",
    "                short = x\n",
    "            else:\n",
    "                x = keras.layers.Conv2D(filters=channel,\n",
    "                                        kernel_size=(3, 3),\n",
    "                                        padding='same',\n",
    "                                        name=f'stage{stage_num}_{cnn_num+1}_conv1',\n",
    "                                        )(x)\n",
    "                x = keras.layers.BatchNormalization(name=f'stage{stage_num}_{cnn_num+1}_bn1')(x)\n",
    "                x = keras.layers.Activation('relu')(x)\n",
    "                x = keras.layers.Conv2D(filters=channel,\n",
    "                                        kernel_size=(3, 3),\n",
    "                                        padding='same',\n",
    "                                        name=f'stage{stage_num}_{cnn_num+1}_conv2',\n",
    "                                        )(x)\n",
    "                x = keras.layers.BatchNormalization(name=f'stage{stage_num}_{cnn_num+1}_bn2')(x)\n",
    "                if is_plain == False:\n",
    "                    x = keras.layers.Add()([x, short])\n",
    "                x = keras.layers.Activation('relu')(x)\n",
    "                short = x\n",
    "    else:\n",
    "        for cnn_num in range(num_cnn):\n",
    "            if cnn_num == 0:\n",
    "                if stage_num == 2:\n",
    "                    stride = 1\n",
    "                else:\n",
    "                    stride = 2\n",
    "                x = keras.layers.Conv2D(filters=channel,\n",
    "                                        kernel_size=(1, 1),\n",
    "                                        strides = stride,\n",
    "                                        padding='same',\n",
    "                                        name=f'stage{stage_num}_{cnn_num+1}_conv1',\n",
    "                                       )(x)\n",
    "                x = keras.layers.BatchNormalization(name=f'stage{stage_num}_{cnn_num+1}_bn1')(x)\n",
    "                x = keras.layers.Activation('relu')(x)\n",
    "                x = keras.layers.Conv2D(filters=channel,\n",
    "                                        kernel_size=(3, 3),\n",
    "                                        padding='same',\n",
    "                                        name=f'stage{stage_num}_{cnn_num+1}_conv2',\n",
    "                                       )(x)\n",
    "                x = keras.layers.BatchNormalization(name=f'stae{stage_num}_{cnn_num+1}_bn2')(x)\n",
    "                x = keras.layers.Activation('relu')(x)\n",
    "                x = keras.layers.Conv2D(filters=channel*4,\n",
    "                                        kernel_size=(1, 1),\n",
    "                                        padding='same',\n",
    "                                        name=f'stage{stage_num}_{cnn_num+1}_conv3',\n",
    "                                       )(x)\n",
    "                x = keras.layers.BatchNormalization(name=f'stage{stage_num}_{cnn_num+1}_bn3')(x)\n",
    "                if is_plain == False:\n",
    "                    short = keras.layers.Conv2D(filters=channel*4,\n",
    "                                                kernel_size=(1, 1),\n",
    "                                                strides=stride,\n",
    "                                                padding='same',\n",
    "                                                name=f'stage{stage_num}_{cnn_num+1}_short',\n",
    "                                                )(short)\n",
    "                    short = keras.layers.BatchNormalization(name=f'stage{stage_num}_{cnn_num+1}_bn4')(short)\n",
    "                    x = keras.layers.Add()([x, short])\n",
    "                x = keras.layers.Activation('relu')(x)\n",
    "                short = x\n",
    "            else:\n",
    "                x = keras.layers.Conv2D(filters=channel,\n",
    "                                        kernel_size=(1, 1),\n",
    "                                        padding='same',\n",
    "                                        name=f'stage{stage_num}_{cnn_num+1}_conv1',\n",
    "                                       )(x)\n",
    "                x = keras.layers.BatchNormalization(name=f'stage{stage_num}_{cnn_num+1}_bn1')(x)\n",
    "                x = keras.layers.Activation('relu')(x)\n",
    "                x = keras.layers.Conv2D(filters=channel,\n",
    "                                        kernel_size=(3, 3),\n",
    "                                        padding='same',\n",
    "                                        name=f'stage{stage_num}_{cnn_num+1}_conv2',\n",
    "                                       )(x)\n",
    "                x = keras.layers.BatchNormalization(name=f'stae{stage_num}_{cnn_num+1}_bn2')(x)\n",
    "                x = keras.layers.Activation('relu')(x)\n",
    "                x = keras.layers.Conv2D(filters=channel*4,\n",
    "                                        kernel_size=(1, 1),\n",
    "                                        padding='same',\n",
    "                                        name=f'stage{stage_num}_{cnn_num+1}_conv3',\n",
    "                                       )(x)\n",
    "                x = keras.layers.BatchNormalization(name=f'stage{stage_num}_{cnn_num+1}_bn3')(x)\n",
    "                if is_plain == False:\n",
    "                    x = keras.layers.Add()([x, short])\n",
    "                x = keras.layers.Activation('relu')(x)\n",
    "                short = x\n",
    "    return x\n",
    "'''\n",
    "def build_ResNet_block(input_layer,\n",
    "                    num_cnn=3, \n",
    "                    channel=64,\n",
    "                    block_num=1,\n",
    "                   ):\n",
    "    # 입력 레이어\n",
    "    #x = keras.layers.ZeroPadding2D(padding=(3, 3))(input_layer)\n",
    "    x = keras.layers.Conv2D(64, (7, 7), strides=(2, 2))(input_layer)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    #x = keras.layers.ZeroPadding2D(padding=(1,1))(x)\n",
    "    # Max Pooling 레이어\n",
    "    x = keras.layers.MaxPooling2D(\n",
    "        pool_size=(2, 2),\n",
    "        strides=2,\n",
    "        name=f'block{block_num}_pooling'\n",
    "    )(x)\n",
    "    \n",
    "    # CNN 레이어\n",
    "    for cnn_num in range(num_cnn):\n",
    "        x = keras.layers.Conv2D(\n",
    "            filters=channel,\n",
    "            kernel_size=(3,3),\n",
    "            activation='relu',\n",
    "            kernel_initializer='he_normal',\n",
    "            padding='same',\n",
    "            name=f'block{block_num}_conv{cnn_num}'\n",
    "        )(x)    \n",
    "        \n",
    "    x = keras.layers.BatchNormalization(axis = 3)(x)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    return x\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG 모델 자체를 생성하는 함수입니다.\n",
    "def build_resnet(input_shape=(224, 224, 3), is_50=False, is_plain=True):\n",
    "    num_cnn_ls = [3, 4, 6, 3]\n",
    "    channel_ls = [64, 128, 256, 512]\n",
    "    num_classes = 2\n",
    "    input_layer = keras.layers.Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "    x = keras.layers.Conv2D(filters = 64,\n",
    "                            kernel_size=(7, 7),\n",
    "                            strides=2,\n",
    "                            kernel_initializer='he_normal',\n",
    "                            padding='same',\n",
    "                            name=f'conv2d_0',\n",
    "                            )(x)\n",
    "    x = keras.layers.BatchNormalization(name=f'batch_normalization_0')(x)\n",
    "    x = keras.layers.Activation('relu', name=f'activation_0')(x)\n",
    "    x = keras.layers.MaxPool2D(pool_size=(3,3), strides=2, padding='same', name=f'stage2_0_maxpooling')(x)\n",
    "    output = x\n",
    "    for i, (num_cnn, channel) in enumerate(zip(num_cnn_ls, channel_ls)):\n",
    "        output = build_ResNet_block(output,\n",
    "                                    num_cnn=num_cnn,\n",
    "                                    stage_num = i+2,\n",
    "                                    channel=channel,\n",
    "                                    is_50 = is_50,\n",
    "                                    is_plain = is_plain,\n",
    "                                    )\n",
    "    output = keras.layers.AveragePooling2D(pool_size = 1,\n",
    "                                           padding='same',\n",
    "                                           name='avg_pool')(output)\n",
    "    output = keras.layers.Flatten(name='flatten_6')(output)\n",
    "    output = keras.layers.Dense(num_classes, activation='softmax',name='predictions')(output)\n",
    "    model = keras.Model(inputs=input_layer, outputs=output)\n",
    "    return model\n",
    "'''\n",
    "def build_resnet(input_shape=(32,32,3),\n",
    "              num_cnn_list=[3,4,6,3],\n",
    "              channel_list=[64,128,256,512],\n",
    "              num_classes=10,\n",
    "              is_50 = False):\n",
    "    \n",
    "    assert len(num_cnn_list) == len(channel_list) #모델을 만들기 전에 config list들이 같은 길이인지 확인합니다.\n",
    "    \n",
    "    input_layer = keras.layers.Input(shape=input_shape)  # input layer를 만들어둡니다.\n",
    "    output = input_layer\n",
    "    \n",
    "    # config list들의 길이만큼 반복해서 블록을 생성합니다.\n",
    "    for i, (num_cnn, channel) in enumerate(zip(num_cnn_list, channel_list)):\n",
    "        output = build_ResNet_block(\n",
    "            output,\n",
    "            num_cnn=num_cnn, \n",
    "            channel=channel,\n",
    "            block_num=i\n",
    "        )\n",
    "        \n",
    "    output = keras.layers.Flatten(name='flatten')(output)\n",
    "    output = keras.layers.Dense(4096, activation='relu', name='fc1')(output)\n",
    "    output = keras.layers.Dense(4096, activation='relu', name='fc2')(output)\n",
    "    output = keras.layers.Dense(num_classes, activation='softmax', name='predictions')(output)\n",
    "    \n",
    "    model = keras.Model(\n",
    "        inputs=input_layer, \n",
    "        outputs=output\n",
    "    )\n",
    "    return model\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_34 = build_resnet(input_shape=(32, 32,3), is_50=False)\n",
    "resnet_34.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
