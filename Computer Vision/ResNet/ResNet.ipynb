{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef build_ResNet_block(input_layer,\\n                    num_cnn=3, \\n                    channel=64,\\n                    block_num=1,\\n                   ):\\n    # 입력 레이어\\n    #x = keras.layers.ZeroPadding2D(padding=(3, 3))(input_layer)\\n    x = keras.layers.Conv2D(64, (7, 7), strides=(2, 2))(input_layer)\\n    x = keras.layers.BatchNormalization()(x)\\n    x = keras.layers.Activation('relu')(x)\\n    #x = keras.layers.ZeroPadding2D(padding=(1,1))(x)\\n    # Max Pooling 레이어\\n    x = keras.layers.MaxPooling2D(\\n        pool_size=(2, 2),\\n        strides=2,\\n        name=f'block{block_num}_pooling'\\n    )(x)\\n    \\n    # CNN 레이어\\n    for cnn_num in range(num_cnn):\\n        x = keras.layers.Conv2D(\\n            filters=channel,\\n            kernel_size=(3,3),\\n            activation='relu',\\n            kernel_initializer='he_normal',\\n            padding='same',\\n            name=f'block{block_num}_conv{cnn_num}'\\n        )(x)    \\n        \\n    x = keras.layers.BatchNormalization(axis = 3)(x)\\n    \\n    \\n\\n    \\n    return x\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function for building ResNet Block\n",
    "def build_ResNet_block(input_layer ,num_cnn=2,stage_num=2, channel=64, is_50=False):\n",
    "    x = input_layer\n",
    "    short = x\n",
    "    if not is_50:\n",
    "        for cnn_num in range(num_cnn):\n",
    "            if stage_num == 2:\n",
    "                stride = 1\n",
    "            else:\n",
    "                stride = 2\n",
    "\n",
    "            x = keras.layers.Conv2D(filters=channel,\n",
    "                                    kernel_size=(3, 3),\n",
    "                                    padding='same',\n",
    "                                    strides=stride,\n",
    "                                    name=f'stage{stage_num}_{cnn_num+1}_conv1',\n",
    "                                    )(x)\n",
    "            x = keras.layers.BatchNormalization(name=f'stage{stage_num}_{cnn_num+1}_bn1')(x)\n",
    "            x = keras.layers.Activation('relu')(x)\n",
    "            x = keras.layers.Conv2D(filters=channel,\n",
    "                                    kernel_size=(3, 3),\n",
    "                                    padding='same',\n",
    "                                    name=f'stage{stage_num}_{cnn_num+1}_conv2',\n",
    "                                    )(x)\n",
    "            x = keras.layers.BatchNormalization(name=f'stage{stage_num}_{cnn_num+1}_bn2')(x)                    \n",
    "            x = keras.layers.Activation('relu')(x)\n",
    "            x = keras.layers.Add()([x, short])\n",
    "            x = keras.layers.Activation('relu')(x)\n",
    "                \n",
    "    else:\n",
    "        print(\"else문\")\n",
    "    return x\n",
    "'''\n",
    "def build_ResNet_block(input_layer,\n",
    "                    num_cnn=3, \n",
    "                    channel=64,\n",
    "                    block_num=1,\n",
    "                   ):\n",
    "    # 입력 레이어\n",
    "    #x = keras.layers.ZeroPadding2D(padding=(3, 3))(input_layer)\n",
    "    x = keras.layers.Conv2D(64, (7, 7), strides=(2, 2))(input_layer)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    #x = keras.layers.ZeroPadding2D(padding=(1,1))(x)\n",
    "    # Max Pooling 레이어\n",
    "    x = keras.layers.MaxPooling2D(\n",
    "        pool_size=(2, 2),\n",
    "        strides=2,\n",
    "        name=f'block{block_num}_pooling'\n",
    "    )(x)\n",
    "    \n",
    "    # CNN 레이어\n",
    "    for cnn_num in range(num_cnn):\n",
    "        x = keras.layers.Conv2D(\n",
    "            filters=channel,\n",
    "            kernel_size=(3,3),\n",
    "            activation='relu',\n",
    "            kernel_initializer='he_normal',\n",
    "            padding='same',\n",
    "            name=f'block{block_num}_conv{cnn_num}'\n",
    "        )(x)    \n",
    "        \n",
    "    x = keras.layers.BatchNormalization(axis = 3)(x)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    return x\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet_input_layer = keras.layers.Input(shape=(32,32,3))   # 입력 레이어 생성\n",
    "ResNet_block_output = build_ResNet_block(ResNet_input_layer)    # VGG 블록 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 블록 1개짜리 model 생성\n",
    "model = keras.Model(inputs=ResNet_input_layer, outputs=ResNet_block_output)  \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet - 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef build_resnet(input_shape=(32,32,3),\\n              num_cnn_list=[3,4,6,3],\\n              channel_list=[64,128,256,512],\\n              num_classes=10,\\n              is_50 = False):\\n    \\n    assert len(num_cnn_list) == len(channel_list) #모델을 만들기 전에 config list들이 같은 길이인지 확인합니다.\\n    \\n    input_layer = keras.layers.Input(shape=input_shape)  # input layer를 만들어둡니다.\\n    output = input_layer\\n    \\n    # config list들의 길이만큼 반복해서 블록을 생성합니다.\\n    for i, (num_cnn, channel) in enumerate(zip(num_cnn_list, channel_list)):\\n        output = build_ResNet_block(\\n            output,\\n            X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\\n            num_cnn=num_cnn, \\n            channel=channel,\\n            block_num=i\\n        )\\n        \\n    output = keras.layers.Flatten(name='flatten')(output)\\n    output = keras.layers.Dense(4096, activation='relu', name='fc1')(output)\\n    output = keras.layers.Dense(4096, activation='relu', name='fc2')(output)\\n    output = keras.layers.Dense(num_classes, activation='softmax', name='predictions')(output)\\n    \\n    model = keras.Model(\\n        inputs=input_layer, \\n        outputs=output\\n    )\\n    return model\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VGG 모델 자체를 생성하는 함수입니다.\n",
    "def build_resnet(input_shape=(224, 224, 3), is_50=False):\n",
    "    num_cnn_ls = [3, 4, 6, 3]\n",
    "    channel_ls = [64, 128, 256, 512]\n",
    "    num_classes = 2\n",
    "    \n",
    "    input_layer = keras.layers.Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "    x = keras.layers.Conv2D(filters = 64,\n",
    "                            kernel_size=(7, 7),\n",
    "                            strides=2,\n",
    "                            kernel_initializer='he_normal',\n",
    "                            padding='same',\n",
    "                            name=f'conv2d_0',\n",
    "                            )(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x) \n",
    "    # x = keras.layers.MaxPool2D(pool_size=(3,3), strides=2, padding='same', name=f'stage2_0_maxpooling')(x) \n",
    "    output = x\n",
    "    \n",
    "    for i, (num_cnn, channel) in enumerate(zip(num_cnn_ls, channel_ls)):\n",
    "        output = build_ResNet_block(output,\n",
    "                                    num_cnn=num_cnn,\n",
    "                                    stage_num = i+2,\n",
    "                                    channel=channel,\n",
    "                                    is_50 = is_50\n",
    "                                )\n",
    "        \n",
    "    output = keras.layers.Activation('relu')(output)\n",
    "    output = keras.layers.AveragePooling2D(pool_size = 1,\n",
    "                                           padding='same',\n",
    "                                           name='avg_pool')(output)\n",
    "    output = keras.layers.Flatten(name='flatten_6')(output)\n",
    "    output = keras.layers.Dense(num_classes, activation='softmax',name='predictions')(output)\n",
    "    model = keras.Model(inputs=input_layer, outputs=output)\n",
    "    return model\n",
    "'''\n",
    "def build_resnet(input_shape=(32,32,3),\n",
    "              num_cnn_list=[3,4,6,3],\n",
    "              channel_list=[64,128,256,512],\n",
    "              num_classes=10,\n",
    "              is_50 = False):\n",
    "    \n",
    "    assert len(num_cnn_list) == len(channel_list) #모델을 만들기 전에 config list들이 같은 길이인지 확인합니다.\n",
    "    \n",
    "    input_layer = keras.layers.Input(shape=input_shape)  # input layer를 만들어둡니다.\n",
    "    output = input_layer\n",
    "    \n",
    "    # config list들의 길이만큼 반복해서 블록을 생성합니다.\n",
    "    for i, (num_cnn, channel) in enumerate(zip(num_cnn_list, channel_list)):\n",
    "        output = build_ResNet_block(\n",
    "            output,\n",
    "            X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "            num_cnn=num_cnn, \n",
    "            channel=channel,\n",
    "            block_num=i\n",
    "        )\n",
    "        \n",
    "    output = keras.layers.Flatten(name='flatten')(output)\n",
    "    output = keras.layers.Dense(4096, activation='relu', name='fc1')(output)\n",
    "    output = keras.layers.Dense(4096, activation='relu', name='fc2')(output)\n",
    "    output = keras.layers.Dense(num_classes, activation='softmax', name='predictions')(output)\n",
    "    \n",
    "    model = keras.Model(\n",
    "        inputs=input_layer, \n",
    "        outputs=output\n",
    "    )\n",
    "    return model\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Operands could not be broadcast together with shapes (4, 4, 128) (8, 8, 64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4676099ea9d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresnet_34\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_resnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_50\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresnet_34\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-da823ad62022>\u001b[0m in \u001b[0;36mbuild_resnet\u001b[0;34m(input_shape, is_50)\u001b[0m\n\u001b[1;32m     24\u001b[0m                                     \u001b[0mstage_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                                     \u001b[0mchannel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                                     \u001b[0mis_50\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                                 )\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-6f8dde68e31d>\u001b[0m in \u001b[0;36mbuild_ResNet_block\u001b[0;34m(input_layer, num_cnn, stage_num, channel, is_50)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'stage{stage_num}_{cnn_num+1}_bn2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshort\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mshort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    895\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2414\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2415\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2416\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2417\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(instance, input_shape)\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_tuples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m     \u001b[0;31m# Return shapes from `fn` as TensorShapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/merge.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    110\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m       \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_elemwise_op_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[0;31m# If the inputs have different ranks, we have to reshape them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;31m# to make them broadcastable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/merge.py\u001b[0m in \u001b[0;36m_compute_elemwise_op_output_shape\u001b[0;34m(self, shape1, shape2)\u001b[0m\n\u001b[1;32m     83\u001b[0m           raise ValueError(\n\u001b[1;32m     84\u001b[0m               \u001b[0;34m'Operands could not be broadcast '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m               'together with shapes ' + str(shape1) + ' ' + str(shape2))\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0moutput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Operands could not be broadcast together with shapes (4, 4, 128) (8, 8, 64)"
     ]
    }
   ],
   "source": [
    "resnet_34 = build_resnet(input_shape=(32, 32,3), is_50=False)\n",
    "resnet_34.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(resnet_34, \"resnet_34.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "build_plaingnet()을 만들기 위한 백업 코드\n",
    "'''\n",
    "# function for building VResNet Block\n",
    "def build_ResNet_block(input_layer ,num_cnn=2,stage_num=2, channel=64, is_50=False, is_plain=True):\n",
    "    x = input_layer\n",
    "    short = x\n",
    "    if not is_50:\n",
    "        for cnn_num in range(num_cnn):\n",
    "            if cnn_num == 0:\n",
    "                if stage_num == 2:\n",
    "                    stride = 1\n",
    "                else:\n",
    "                    stride = 2\n",
    "                    \n",
    "                x = keras.layers.Conv2D(filters=channel,\n",
    "                                        kernel_size=(3, 3),\n",
    "                                        padding='same',\n",
    "                                        strides=stride,\n",
    "                                        name=f'stage{stage_num}_{cnn_num+1}_conv1',\n",
    "                                        )(x)\n",
    "                x = keras.layers.BatchNormalization(name=f'stage{stage_num}_{cnn_num+1}_bn1')(x)\n",
    "                x = keras.layers.Activation('relu')(x)\n",
    "                x = keras.layers.Conv2D(filters=channel,\n",
    "                                        kernel_size=(3, 3),\n",
    "                                        padding='same',\n",
    "                                        name=f'stage{stage_num}_{cnn_num+1}_conv2',\n",
    "                                        )(x)\n",
    "                x = keras.layers.BatchNormalization(name=f'stage{stage_num}_{cnn_num+1}_bn2')(x)\n",
    "                \n",
    "                if is_plain == False:\n",
    "                    short = keras.layers.Conv2D(filters=channel,\n",
    "                                                kernel_size=(1, 1),\n",
    "                                                strides=stride,\n",
    "                                                padding='same',\n",
    "                                                name=f'stage{stage_num}_{cnn_num+1}_short',\n",
    "                                                )(short)\n",
    "                    short = keras.layers.BatchNormalization(name=f'stage{stage_num}_{cnn_num+1}_bn3')(short)\n",
    "                    x = keras.layers.Add()([x, short])\n",
    "                    \n",
    "                x = keras.layers.Activation('relu')(x)\n",
    "                short = x\n",
    "            else:\n",
    "                x = keras.layers.Conv2D(filters=channel,\n",
    "                                        kernel_size=(3, 3),\n",
    "                                        padding='same',\n",
    "                                        name=f'stage{stage_num}_{cnn_num+1}_conv1',\n",
    "                                        )(x)\n",
    "                x = keras.layers.BatchNormalization(name=f'stage{stage_num}_{cnn_num+1}_bn1')(x)\n",
    "                x = keras.layers.Activation('relu')(x)\n",
    "                x = keras.layers.Conv2D(filters=channel,\n",
    "                                        kernel_size=(3, 3),\n",
    "                                        padding='same',\n",
    "                                        name=f'stage{stage_num}_{cnn_num+1}_conv2',\n",
    "                                        )(x)\n",
    "                x = keras.layers.BatchNormalization(name=f'stage{stage_num}_{cnn_num+1}_bn2')(x)\n",
    "                if is_plain == False:\n",
    "                    x = keras.layers.Add()([x, short])\n",
    "                x = keras.layers.Activation('relu')(x)\n",
    "                short = x\n",
    "    else:\n",
    "        for cnn_num in range(num_cnn):\n",
    "            if cnn_num == 0:\n",
    "                if stage_num == 2:\n",
    "                    stride = 1\n",
    "                else:\n",
    "                    stride = 2\n",
    "                x = keras.layers.Conv2D(filters=channel,\n",
    "                                        kernel_size=(1, 1),\n",
    "                                        strides = stride,\n",
    "                                        padding='same',\n",
    "                                        name=f'stage{stage_num}_{cnn_num+1}_conv1',\n",
    "                                       )(x)\n",
    "                x = keras.layers.BatchNormalization(name=f'stage{stage_num}_{cnn_num+1}_bn1')(x)\n",
    "                x = keras.layers.Activation('relu')(x)\n",
    "                x = keras.layers.Conv2D(filters=channel,\n",
    "                                        kernel_size=(3, 3),\n",
    "                                        padding='same',\n",
    "                                        name=f'stage{stage_num}_{cnn_num+1}_conv2',\n",
    "                                       )(x)\n",
    "                x = keras.layers.BatchNormalization(name=f'stae{stage_num}_{cnn_num+1}_bn2')(x)\n",
    "                x = keras.layers.Activation('relu')(x)\n",
    "                x = keras.layers.Conv2D(filters=channel*4,\n",
    "                                        kernel_size=(1, 1),\n",
    "                                        padding='same',\n",
    "                                        name=f'stage{stage_num}_{cnn_num+1}_conv3',\n",
    "                                       )(x)\n",
    "                x = keras.layers.BatchNormalization(name=f'stage{stage_num}_{cnn_num+1}_bn3')(x)\n",
    "                if is_plain == False:\n",
    "                    short = keras.layers.Conv2D(filters=channel*4,\n",
    "                                                kernel_size=(1, 1),\n",
    "                                                strides=stride,\n",
    "                                                padding='same',\n",
    "                                                name=f'stage{stage_num}_{cnn_num+1}_short',\n",
    "                                                )(short)\n",
    "                    short = keras.layers.BatchNormalization(name=f'stage{stage_num}_{cnn_num+1}_bn4')(short)\n",
    "                    x = keras.layers.Add()([x, short])\n",
    "                x = keras.layers.Activation('relu')(x)\n",
    "                short = x\n",
    "            else:\n",
    "                x = keras.layers.Conv2D(filters=channel,\n",
    "                                        kernel_size=(1, 1),\n",
    "                                        padding='same',\n",
    "                                        name=f'stage{stage_num}_{cnn_num+1}_conv1',\n",
    "                                       )(x)\n",
    "                x = keras.layers.BatchNormalization(name=f'stage{stage_num}_{cnn_num+1}_bn1')(x)\n",
    "                x = keras.layers.Activation('relu')(x)\n",
    "                x = keras.layers.Conv2D(filters=channel,\n",
    "                                        kernel_size=(3, 3),\n",
    "                                        padding='same',\n",
    "                                        name=f'stage{stage_num}_{cnn_num+1}_conv2',\n",
    "                                       )(x)\n",
    "                x = keras.layers.BatchNormalization(name=f'stae{stage_num}_{cnn_num+1}_bn2')(x)\n",
    "                x = keras.layers.Activation('relu')(x)\n",
    "                x = keras.layers.Conv2D(filters=channel*4,\n",
    "                                        kernel_size=(1, 1),\n",
    "                                        padding='same',\n",
    "                                        name=f'stage{stage_num}_{cnn_num+1}_conv3',\n",
    "                                       )(x)\n",
    "                x = keras.layers.BatchNormalization(name=f'stage{stage_num}_{cnn_num+1}_bn3')(x)\n",
    "                if is_plain == False:\n",
    "                    x = keras.layers.Add()([x, short])\n",
    "                x = keras.layers.Activation('relu')(x)\n",
    "                short = x\n",
    "    return x\n",
    "'''\n",
    "def build_ResNet_block(input_layer,\n",
    "                    num_cnn=3, \n",
    "                    channel=64,\n",
    "                    block_num=1,\n",
    "                   ):\n",
    "    # 입력 레이어\n",
    "    #x = keras.layers.ZeroPadding2D(padding=(3, 3))(input_layer)\n",
    "    x = keras.layers.Conv2D(64, (7, 7), strides=(2, 2))(input_layer)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    #x = keras.layers.ZeroPadding2D(padding=(1,1))(x)\n",
    "    # Max Pooling 레이어\n",
    "    x = keras.layers.MaxPooling2D(\n",
    "        pool_size=(2, 2),\n",
    "        strides=2,\n",
    "        name=f'block{block_num}_pooling'\n",
    "    )(x)\n",
    "    \n",
    "    # CNN 레이어\n",
    "    for cnn_num in range(num_cnn):\n",
    "        x = keras.layers.Conv2D(\n",
    "            filters=channel,\n",
    "            kernel_size=(3,3),\n",
    "            activation='relu',\n",
    "            kernel_initializer='he_normal',\n",
    "            padding='same',\n",
    "            name=f'block{block_num}_conv{cnn_num}'\n",
    "        )(x)    \n",
    "        \n",
    "    x = keras.layers.BatchNormalization(axis = 3)(x)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    return x\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG 모델 자체를 생성하는 함수입니다.\n",
    "def build_resnet(input_shape=(224, 224, 3), is_50=False, is_plain=True):\n",
    "    num_cnn_ls = [3, 4, 6, 3]\n",
    "    channel_ls = [64, 128, 256, 512]\n",
    "    num_classes = 2\n",
    "    input_layer = keras.layers.Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "    x = keras.layers.Conv2D(filters = 64,\n",
    "                            kernel_size=(7, 7),\n",
    "                            strides=2,\n",
    "                            kernel_initializer='he_normal',\n",
    "                            padding='same',\n",
    "                            name=f'conv2d_0',\n",
    "                            )(x)\n",
    "    x = keras.layers.BatchNormalization(name=f'batch_normalization_0')(x)\n",
    "    x = keras.layers.Activation('relu', name=f'activation_0')(x)\n",
    "    x = keras.layers.MaxPool2D(pool_size=(3,3), strides=2, padding='same', name=f'stage2_0_maxpooling')(x)\n",
    "    output = x\n",
    "    for i, (num_cnn, channel) in enumerate(zip(num_cnn_ls, channel_ls)):\n",
    "        output = build_ResNet_block(output,\n",
    "                                    num_cnn=num_cnn,\n",
    "                                    stage_num = i+2,\n",
    "                                    channel=channel,\n",
    "                                    is_50 = is_50,\n",
    "                                    is_plain = is_plain,\n",
    "                                    )\n",
    "    output = keras.layers.AveragePooling2D(pool_size = 1,\n",
    "                                           padding='same',\n",
    "                                           name='avg_pool')(output)\n",
    "    output = keras.layers.Flatten(name='flatten_6')(output)\n",
    "    output = keras.layers.Dense(num_classes, activation='softmax',name='predictions')(output)\n",
    "    model = keras.Model(inputs=input_layer, outputs=output)\n",
    "    return model\n",
    "'''\n",
    "def build_resnet(input_shape=(32,32,3),\n",
    "              num_cnn_list=[3,4,6,3],\n",
    "              channel_list=[64,128,256,512],\n",
    "              num_classes=10,\n",
    "              is_50 = False):\n",
    "    \n",
    "    assert len(num_cnn_list) == len(channel_list) #모델을 만들기 전에 config list들이 같은 길이인지 확인합니다.\n",
    "    \n",
    "    input_layer = keras.layers.Input(shape=input_shape)  # input layer를 만들어둡니다.\n",
    "    output = input_layer\n",
    "    \n",
    "    # config list들의 길이만큼 반복해서 블록을 생성합니다.\n",
    "    for i, (num_cnn, channel) in enumerate(zip(num_cnn_list, channel_list)):\n",
    "        output = build_ResNet_block(\n",
    "            output,\n",
    "            num_cnn=num_cnn, \n",
    "            channel=channel,\n",
    "            block_num=i\n",
    "        )\n",
    "        \n",
    "    output = keras.layers.Flatten(name='flatten')(output)\n",
    "    output = keras.layers.Dense(4096, activation='relu', name='fc1')(output)\n",
    "    output = keras.layers.Dense(4096, activation='relu', name='fc2')(output)\n",
    "    output = keras.layers.Dense(num_classes, activation='softmax', name='predictions')(output)\n",
    "    \n",
    "    model = keras.Model(\n",
    "        inputs=input_layer, \n",
    "        outputs=output\n",
    "    )\n",
    "    return model\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_34 = build_resnet(input_shape=(32, 32,3), is_50=False)\n",
    "resnet_34.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
